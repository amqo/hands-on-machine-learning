{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacf33b9-dd62-4a57-a723-30b56bffbb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.10.0', '2.10.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf83a7-4a9d-4a3f-b5e4-1e36e1eff5ae",
   "metadata": {},
   "source": [
    "Classification DNN using Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda5f200-672d-41b0-8e62-147b228968d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6bcb71-b3a1-4d44-9e15-222b670a6562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ecff92-e3e5-460a-b9ad-0b6cab804122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86aafad-fe14-47d3-9874-7e2cacf02dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882e3cd0-3f69-4ee9-95de-12a6f2df2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 'Coat')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa12427-57df-401d-9030-4bd87c16da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (28, 28)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Image shape: \" + str(X_train[0].shape) + \"\\n\")\n",
    "\n",
    "plt.figure(figsize=(1, 1))\n",
    "plt.imshow(X_train[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44594d2a-fdc9-4582-9fc6-0f26af7168b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:16:34.325936: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-22 13:16:34.326261: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7244e453-c19f-422c-b242-a4b91d9f36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way of doing the same:\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee5b98f3-1949-40ac-8575-d9ad531483a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a93f26a-0a2f-4c2f-bcdd-fd34a09e7079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x2c41f6760>,\n",
       " <keras.layers.core.dense.Dense at 0x2c41f6e20>,\n",
       " <keras.layers.core.dense.Dense at 0x2c41f6490>,\n",
       " <keras.layers.core.dense.Dense at 0x2c41f6670>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f28d5352-906c-4a8c-afa6-800045011818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23d69493-0121-43b1-af56-6d573b99ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09ae8f45-f4dd-4e42-9c41-fdfa2a48e944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00514141,  0.02194236, -0.01781379, ...,  0.07382935,\n",
       "         -0.02373501,  0.06358339],\n",
       "        [-0.03367042,  0.01164905, -0.05591521, ..., -0.05726631,\n",
       "         -0.01404398,  0.00208317],\n",
       "        [-0.03174377,  0.07203485, -0.01024017, ...,  0.02401216,\n",
       "         -0.00873   ,  0.04127569],\n",
       "        ...,\n",
       "        [-0.00272794, -0.05984571, -0.01982886, ..., -0.00322458,\n",
       "         -0.04756613,  0.06375334],\n",
       "        [-0.00157102, -0.02240926, -0.02162092, ..., -0.02173708,\n",
       "         -0.02743725, -0.00642075],\n",
       "        [-0.02475765, -0.01893289,  0.03171214, ...,  0.03322469,\n",
       "         -0.06970531,  0.0434451 ]], dtype=float32),\n",
       " (784, 300))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc3047f0-f892-417e-a953-12a7cf45698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " (300,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fe92b60-932b-44d1-b4c2-9a816610a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc26faa4-eca6-490d-b61b-88ab2de7e836",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:35:13.693673: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-22 13:35:13.831804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.7603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:35:23.813708: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 11s 5ms/step - loss: 0.7339 - accuracy: 0.7603 - val_loss: 0.5025 - val_accuracy: 0.8300\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4890 - accuracy: 0.8298 - val_loss: 0.4492 - val_accuracy: 0.8476\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4443 - accuracy: 0.8434 - val_loss: 0.4222 - val_accuracy: 0.8546\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4175 - accuracy: 0.8532 - val_loss: 0.3983 - val_accuracy: 0.8642\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3967 - accuracy: 0.8602 - val_loss: 0.3932 - val_accuracy: 0.8678\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3811 - accuracy: 0.8655 - val_loss: 0.3900 - val_accuracy: 0.8634\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3673 - accuracy: 0.8702 - val_loss: 0.3700 - val_accuracy: 0.8690\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3558 - accuracy: 0.8736 - val_loss: 0.3614 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3457 - accuracy: 0.8779 - val_loss: 0.3425 - val_accuracy: 0.8796\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3354 - accuracy: 0.8802 - val_loss: 0.3381 - val_accuracy: 0.8786\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3255 - accuracy: 0.8849 - val_loss: 0.3443 - val_accuracy: 0.8808\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3180 - accuracy: 0.8853 - val_loss: 0.3457 - val_accuracy: 0.8754\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3099 - accuracy: 0.8885 - val_loss: 0.3428 - val_accuracy: 0.8720\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3039 - accuracy: 0.8906 - val_loss: 0.3379 - val_accuracy: 0.8816\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2973 - accuracy: 0.8932 - val_loss: 0.3208 - val_accuracy: 0.8870\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2900 - accuracy: 0.8946 - val_loss: 0.3194 - val_accuracy: 0.8866\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2840 - accuracy: 0.8973 - val_loss: 0.3086 - val_accuracy: 0.8890\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2792 - accuracy: 0.8990 - val_loss: 0.3143 - val_accuracy: 0.8866\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2737 - accuracy: 0.9012 - val_loss: 0.3149 - val_accuracy: 0.8832\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2687 - accuracy: 0.9027 - val_loss: 0.3051 - val_accuracy: 0.8920\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2636 - accuracy: 0.9044 - val_loss: 0.3494 - val_accuracy: 0.8726\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2595 - accuracy: 0.9050 - val_loss: 0.3026 - val_accuracy: 0.8878\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2547 - accuracy: 0.9079 - val_loss: 0.3056 - val_accuracy: 0.8896\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2502 - accuracy: 0.9092 - val_loss: 0.3016 - val_accuracy: 0.8938\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2468 - accuracy: 0.9103 - val_loss: 0.2981 - val_accuracy: 0.8942\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2417 - accuracy: 0.9132 - val_loss: 0.2983 - val_accuracy: 0.8950\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2380 - accuracy: 0.9145 - val_loss: 0.3033 - val_accuracy: 0.8912\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2341 - accuracy: 0.9157 - val_loss: 0.2879 - val_accuracy: 0.8964\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2299 - accuracy: 0.9166 - val_loss: 0.3044 - val_accuracy: 0.8920\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2269 - accuracy: 0.9183 - val_loss: 0.3258 - val_accuracy: 0.8774\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=30, \n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "737ba5f1-46d2-4b07-8839-932ba1e7a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e4d7421-cf10-43dd-bbfb-077940edc3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3601 - accuracy: 0.8672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36007604002952576, 0.8672000169754028]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ce3a8e-e5e7-477d-8c17-30a6aa1e9b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:59:10.940833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We now make predictions using the trained model\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27e21130-17ff-4338-a626-cd6a38c7cc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAABhCAYAAABs4F42AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAO7klEQVR4nO3dX8zW8x/H8Vc/REVFRYnVqGRCOchufxLZKGE5wUHmpBkHDsxms2kc2XKCAzMb5kQ2YXFgwgylYosIqXQrf5JS+ZN/od+BvT/369v1+XZd1X13f7ru5+Pove91X9/r2/rc9/f6vL/vz/vTb+/evXsFAECB/tfbFwAAQB1uUgCAYnGTAgAUi5sUAKBY3KQAAMXiJgUAKBY3KQBAsbhJAQCKxU0KAFCso3v7AoDS/fLLLyl+//33UzxjxoyWz7Fq1aoUH3/88ZKkCRMmdMPVoZ15Q6B+/fpJkt5888107NFHH03x5MmTU/z9999LksaNG5eO/frrryneuXNnio8++r/bQGdnZzr20ksvHeqldxtmUgCAYnGTAgAUqx8NZtHX/fHHHyl++OGHU7xw4UJJ1dTItm3bUjxgwIAU+8/kHHfccQ1xpFkkadq0aSmeN29eiq+++uqm14/29e+//6b4f//7b05xySWXpGPLli3b7/sHDx6c4t9++y3Ff//9d4pjHP/+++/p2CuvvJLi2bNnH+hldytmUgCAYjGTQp90zz33pPiJJ55I8c8//5zigQMHSqrOmHz249889+zZI0n6559/0rFjjz02xX6O+JX7888/s+fyc3R0dEiS3nnnneb/KPQJJ5xwQoqPOeaYFI8YMSLFu3fvllQdSz6b9/fFeNywYUM69tBDD6X47rvv7o7LPmjMpAAAxeImBQAoFuuk0KdEam/BggXp2MiRI1M8aNCgFMe6FM+IR1pPyhdDxHukrgfdUvVBde79sXZKko466qgUx4Pxa6+9Nh3zh9roe3y90/Dhw1PsqeoouPCUsxdh+Dn8Z8LXX3/dPRfbDZhJAQCKxU0KAFAs0n3oU+677z5J1fUjnqLzaqhoLeOGDh2aYk/XRdWfp1F8/dWwYcMaPsMrBb3Sz9OLp5xyiqRqdd/27dtT7OketLetW7c2HPMx5OM4eJrZK/o8pRzv89+JH3744dAuthsxkwIAFIubFACgWKT70Kf89NNPkqoVTZ5e8xTf7bffLkm67bbb0rELLrggxV4J+M0330iqLrQcM2ZMij1VE58d75Gk0aNHN7wudXVg98W+GzduTDHpvr5jzZo1Dcf69++fYh8jkc7zdKBX9/mYz1UCekq5tzGTAgAUi5kU+pQoUPCih7rOYA8++KAkaciQIemYfxv1hp3Tp0+XJL311lvZc5199tkpXrt2raTqupZHHnkkxVHcIXW1uvGCjqVLl6Z46tSp2c9D+1m9erWk6uzJx7GPxyjaicyBVC3e8SKLXJsuzxL0NmZSAIBicZMCABSrz6b7PH3i7Wtyaw18GuwPF9evXy9JGj9+fE9cIrrJX3/91XDM/5/9/9fdcsstkqTFixdnX/c9pCLNN3/+/HTM150899xzKd6xY4ckadOmTenYjTfemGJP9+XWVH300UfZ60F7++CDDyRV/155is/HSKT5vNDHx82JJ56Y4vib5uc6/fTTu+mqDx0zKQBAsbhJAQCKdcSm+6IixSuzfBr87bffpnj58uWSpJkzZ6ZjB1K9kusSLEkvvviipOoGeijPd99913DMx4qvL3G+jinn+eefbzg2d+7cFPtGh55ePv/88yVJW7ZsSce8C3ozkWZG3/L5559LqrY38nHsLblGjRolSVqxYkU65ilur1KN2FsonXTSSd112YeMmRQAoFjcpAAAxTpi033Bp7vu3XffTfHKlSslVdM+d955Z8uf4R2BX3vttRR7CxyUa9u2bft9va5TdIwXT424yy67rOHYVVddleLOzs4Ue/rk1VdfldS1AFjqSgFK1dRffLZ3rc51Z0f7i4o9Hwt16b4bbrhhv+fyMT9w4MCG13MVsb2FmRQAoFhH7Ewqt34k1hFIXQ8Zpa49efyB85w5c1LsawainYg3B/3xxx9T7K1svCkoyuVFNKGuFZJ/q4wZi39b9fd98cUXKY7iGW/+6nJtkTZv3pyOPfbYYyn2h90xNr14J/fvQfuLJsWtFH3dfPPNDcd8DMVaPSnfpNjXTPU2ZlIAgGJxkwIAFOuISvf5A+xI8+3evTsdW7RoUYp9ahspvNibR6qmbXLxp59+mo6ddtppKfbUoK99QblyhRP+8NkfInscBQz33ntv9vUlS5akODpU+7jx1HCk+KSu1KC3QqprdRRj3te47NmzJ/uzaG+xns8Ltur+Bl1++eUNxzo6OlIca0el6pgO3jG9tzGTAgAUi5sUAKBYhy3d5ym1uvYccdxf9+msp2jC448/nuKo4pOqm4FFt+lI++37sz7djc/2ChpPHfomYtE921OOJW0Whv94+6FQV7HnYyE2O4zND/flmyHGePrss8+yPzty5MgUx9bcPkbr5KpYc69L+d8PtDdP/foYybVyGzt2bIp948xcpauP7d7GTAoAUCxuUgCAYvVIui+X2sttJijl2xq1ksJYuHChpGqLmClTpqTY0za7du2SVG1N49UrkX6RulqL5CpepOq/LRa8+SLhyZMnZ9+H3tOsLVL//v1TfMUVV6Q4Wmt5daePR98sMcZsXTdzH0+RGvT3+/uGDh2a4qj6q+tK/dVXX6X4zDPPzP4M2ov/LfX2Rc3+/30c+9/Yur/NpWAmBQAoVo/MpHJ35tz+JVL1m2m8r2729NRTT6V43bp1kqrbHHv7Ip/xxPoCb2Pka6b8eqMtjhdZ1BV9BG86y0yqPDGTdv7/7+Pi1ltvTXE0gs014JTqx3SOj5uYVflMyh96e3PQZlvFexaAmVTf4GPFi7bOOeec/b5v1qxZKV6wYEGKm43d3sZMCgBQLG5SAIBiHVK6r26a6KmNSJV5gUTdHlDB932KLdql6jbf48ePl1TdQ8XTJ576iz2C/LrquvzGtfk6A79eXwcV51u2bNl+/z3oXT4Wgo+lk08+OcXe9ir4HlO5NXVS8zGdW/vnx3zsXnjhhQ3v9/P7+qrSUzXofl704I8izjjjjP2+z/cs84KLXJFYSes9mUkBAIrFTQoAUKyW0325tUvNUhxSvhrO1634Oo/YRM7b2PgalsGDB6c4Kra807S3CPH0SVyvf5ZPcX1dSnxe3ZR6wIABKc6tjVmzZk2KJ02aJPQ+r+6LVJlXb3pqwzfLDF5NVdeBvNlak2ZrB/0am1XH+rm8ug/tLdY5eUWf/w0+9dRT9/v+utZapPsAADhI3KQAAMVqOd2XW2C7devWFEencak6HY3Yq6k6OztT7FV2MR31Tb08zeEdyON8PoX1c3laLir1vKJl1KhRKfaUYZzDq7y8gnDHjh0pjjSft2by11GGZhVwZ511Voq//PLLhtebde2X8p2k684R6RWvIPX3e7Vh7nP9Z5u1fEL7iHGxcePGdMxTddHgoI4/OnG5NGBd9XNvYCYFACjWQa2TeuONNyRV1zP53di/3UVxgc/E/Gd91hQzFp+Z+LdGL4aImY5/w/QZjxc+xEPAuiaezb6N+qzKH1TGbM5naHUPJ9F76vbcCT6Tevvttxteb6XZcIzDumIi/9mI69p/eSPQiOsKJHzMo71NnTpVUrW4x2fjzVpo1fG/q7nz9jZmUgCAYnGTAgAUq+Xc1JIlS1L85JNPSpImTpyYjnkhQq7wwR/a1a1Bivd5+szTJ965Ot7nBRl1285H+tALPXybb/88f1/wNKEXhcSaG38999AbvcuLaHIpNh9ja9euTXG0Q8qNiVbU7dkTcV1qeMOGDSmObec9Be5tmkp6wI2eNW3aNEnS008/nY7539UPP/yw5XP5mM+ls1tZA3u4lHMlAADsg5sUAKBYLaf7orJEklasWCFJ+uSTT9KxpUuXZt8XqQlPAfpW2B4PGTJEUjX95ulA72YdLZQ83eHrnTy9snr1aknSeeedl46NHTs2xa+//nqKo9KlbrrrKZpoQ+LtmjwliTL4/1kudefVf77OLTY7PJBO461sxR0px7qqwcWLF6c4xumqVavSMR+bO3fubPnacGS76KKLJFW74Hv6+kAeNfjfrNwav5K66zOTAgAUi5sUAKBYLaf7fPHr/PnzG173RYUrV65McaTl3nvvvXTMu5F//PHHKY7KuVzHaKma5og04bnnnpuOXXnllSmeNWtWin16nHPdddelePPmzZKkYcOGpWM+Nfa0ZaSRfOHbhAkT9vtZOPx83Hj38+AVfb6wMf5fPR3o6ZVcmiS3aFdq3tnc+e9HpKgXLVqUPVddV3a0nzFjxkiq/j3y8epjO1on1W2E6BWiuTF0sBWtPYGZFACgWN3Ww8fXCs2YMaMhvuOOO7rro7rdyy+/3NuXgB7kM93c7MWLD/zbaLyvrn2Rz9Aizq2H2jeOGZbPtKJoSJKWL1+e4tzM3M/l6wTRN/jsyYtvvOCs2UzK17XGzN3bvzGTAgCgBdykAADFomU32p4/JI61T17oc9ddd6U4OvxLXam0VlrE5LaEr9tjKtcx3fdKmz59eopnz54tSXrggQfSMU8/5jpYo33kim/mzJmTjj377LMp9lR2rFv1YjIXvwd1n+Wpv97GTAoAUCxuUgCAYpHuQ9vzzvWRKqtbJzJixIgUr1+/XlK1Qupg28Xk0jZ+DV5h6O1thg8f3nAuTxNu2rTpoK4HR4bcuLn++uvTsWeeeSbF3hH9hRdekCTdf//92fPmOvR7qppNDwEAaAE3KQBAsUj3oe1dfPHFKY6Fst4qyxfMrlu37vBdWAtiUaa34/KKPt+dAO3H08uR5p05c2Y65lV4Pi6aVaROmjQpxbGbhf9ObNmy5SCvuPsxkwIAFIuZFNqezzZi7ZM/ZC5pq+x9RVGHf0v29jeDBg067NeEw6euJVeIprNS1z5/Utc+e97YO/ajkqqFE9EKzMfV9u3bD/KKu1+5v50AgD6PmxQAoFik+9D2Ro8eneIpU6ZIqj4krkuZRYfpZntIdQc/r3/euHHjJEnXXHNNOrZr164Ud3R09Mj1oAy5fcjcvHnzUjxx4sQU33TTTZKqKT43d+7cFEdLLt/J4tJLLz3wi+0hzKQAAMXiJgUAKFa/vT2VvwAA4BAxkwIAFIubFACgWNykAADF4iYFACgWNykAQLG4SQEAisVNCgBQLG5SAIBicZMCABTr/zuy4wJTOqefAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 600x100 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig = plt.figure(figsize=(6, 1))\n",
    "for index in range(3):\n",
    "    sub = fig.add_subplot(1, 3, index + 1)\n",
    "    sub.imshow(X_new[index], cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "    sub.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f48df78-2e2c-40a6-bf88-7bfb461d5aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ankle boot', 'Pullover', 'Trouser']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_index = y_proba.argmax(axis=1)\n",
    "[class_names[index] for index in proba_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e1725d0-47a8-477f-b4cb-da130f336ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 2, 1], dtype=uint8), array([9, 2, 1]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3], proba_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e1e4a-0ed0-431c-a33a-1429e02f24b7",
   "metadata": {},
   "source": [
    "Regression DNN using Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e18792c-1a63-402a-9cd7-525995813db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de14cb37-3a71-4e62-99db-33d9635676cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30d0d062-cc2b-4c6e-b682-cdf1d3212b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e3fefc5-28f2-47e4-9ea9-26b3bfdb5493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=\"sgd\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ff4a598-316c-4138-8228-9f3de0fcff23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 45/363 [==>...........................] - ETA: 1s - loss: 2.3776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 14:54:28.347410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - ETA: 0s - loss: 1.4239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 14:54:29.682282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 4ms/step - loss: 1.4239 - val_loss: 0.7082\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5759 - val_loss: 0.4839\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4624 - val_loss: 0.4238\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4297 - val_loss: 0.4056\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4116 - val_loss: 0.3984\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.3848\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3944 - val_loss: 0.3813\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3942 - val_loss: 0.3770\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3976 - val_loss: 0.3780\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3915 - val_loss: 0.3686\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3771 - val_loss: 0.3687\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3766 - val_loss: 0.3639\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3726 - val_loss: 0.3613\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3718 - val_loss: 0.3577\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3653 - val_loss: 0.3543\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3641 - val_loss: 0.3580\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3623 - val_loss: 0.3552\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3783 - val_loss: 0.3495\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3582 - val_loss: 0.3533\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3570 - val_loss: 0.3456\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 20,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8d01f4a-88de-42e5-94ea-86aeae830868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.3695\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "341e9a23-d9da-4cee-98a1-c95d8a546261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.2620873, 1.7111522, 1.8400514], dtype=float32),\n",
       " array([1.518, 1.056, 1.95 ]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe93b4-590d-4d72-912f-252db2d80a96",
   "metadata": {},
   "source": [
    "Building complex models using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67dda9ff-aa2a-4db0-b7a2-729345fe36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "609b08e3-e980-4b46-b4a3-0a826accc8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 30)           270         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 30)           930         ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 38)           0           ['input_2[0][0]',                \n",
      "                                                                  'dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            39          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amqo/Develop/ML/miniconda3/envs/handsOnTensorflow/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2960c398-4f13-4ac8-8298-14ec6978baf1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 27/363 [=>............................] - ETA: 1s - loss: 5.3173 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:08:03.047183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/363 [============================>.] - ETA: 0s - loss: 1.6754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:08:04.554729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 5ms/step - loss: 1.6579 - val_loss: 0.7661\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7173 - val_loss: 0.6787\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6589 - val_loss: 0.6340\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6231 - val_loss: 0.6017\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5944 - val_loss: 0.5768\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5714 - val_loss: 0.5548\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5518 - val_loss: 0.5368\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5356 - val_loss: 0.5210\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5215 - val_loss: 0.5078\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5096 - val_loss: 0.4978\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4995 - val_loss: 0.4874\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4903 - val_loss: 0.4788\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4832 - val_loss: 0.4714\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4762 - val_loss: 0.4646\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4705 - val_loss: 0.4595\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4648 - val_loss: 0.4536\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4606 - val_loss: 0.4496\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4558 - val_loss: 0.4454\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4520 - val_loss: 0.4415\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4480 - val_loss: 0.4373\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 20,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cdc8ae79-ee6f-40e0-9ce9-48e5414a8f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4582\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1012fa73-6667-4a08-9213-47f955c065a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we send a subset of the features through the wide path, and a different one throught the deep path\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "306ac7f7-0fb8-4d13-9aa2-53e11a07a78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 30)           930         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            36          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "103335fb-4ac3-446b-8677-968026999741",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/363 [..............................] - ETA: 1:38 - loss: 4.2121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:13:39.479190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - ETA: 0s - loss: 2.0101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:13:41.196053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 5ms/step - loss: 2.0101 - val_loss: 0.9304\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8550 - val_loss: 0.7605\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7415 - val_loss: 0.6999\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6951 - val_loss: 0.6643\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6630 - val_loss: 0.6377\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6378 - val_loss: 0.6148\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6165 - val_loss: 0.5952\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5989 - val_loss: 0.5802\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5848 - val_loss: 0.5692\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5736 - val_loss: 0.5584\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5635 - val_loss: 0.5510\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5554 - val_loss: 0.5422\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5483 - val_loss: 0.5353\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5416 - val_loss: 0.5298\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5360 - val_loss: 0.5240\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5300 - val_loss: 0.5195\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5255 - val_loss: 0.5137\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5210 - val_loss: 0.5096\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5158 - val_loss: 0.5048\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5120 - val_loss: 0.5009\n"
     ]
    }
   ],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit(\n",
    "    (X_train_A, X_train_B), y_train,\n",
    "    epochs=20,\n",
    "    validation_data=((X_valid_A, X_valid_B), y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d081b817-bac6-4cef-92e2-e0b71ce68414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5212\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1f57934-dcaf-4af0-ae35-5b990477f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x31b4dbaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 15:56:01.172335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91006b0b-b25e-48f2-9d74-e691d9170146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding extra outputs, here we add an aux. output that will make that segment of the network learn something on its own, without dependint on the rest of the network\n",
    "#This aux output can be used for regularization, as a common use case\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7969d84-7bc9-4727-856a-d8719ef287b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 30)           930         ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 1)            36          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " aux_output (Dense)             (None, 1)            31          ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a91d4d0-9c86-489d-8fce-92bf6d324bb2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 10/363 [..............................] - ETA: 2s - loss: 4.0994 - main_output_loss: 3.8440 - aux_output_loss: 6.3984  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:30:16.154605: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - ETA: 0s - loss: 0.9922 - main_output_loss: 0.8372 - aux_output_loss: 2.3874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:30:18.531116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 3s 8ms/step - loss: 0.9922 - main_output_loss: 0.8372 - aux_output_loss: 2.3874 - val_loss: 0.5878 - val_main_output_loss: 0.5304 - val_aux_output_loss: 1.1046\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.5680 - main_output_loss: 0.5154 - aux_output_loss: 1.0419 - val_loss: 0.5096 - val_main_output_loss: 0.4607 - val_aux_output_loss: 0.9496\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.5108 - main_output_loss: 0.4668 - aux_output_loss: 0.9068 - val_loss: 0.4720 - val_main_output_loss: 0.4315 - val_aux_output_loss: 0.8370\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4766 - main_output_loss: 0.4395 - aux_output_loss: 0.8107 - val_loss: 0.4534 - val_main_output_loss: 0.4201 - val_aux_output_loss: 0.7530\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4569 - main_output_loss: 0.4258 - aux_output_loss: 0.7366 - val_loss: 0.4337 - val_main_output_loss: 0.4054 - val_aux_output_loss: 0.6884\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4440 - main_output_loss: 0.4176 - aux_output_loss: 0.6816 - val_loss: 0.4276 - val_main_output_loss: 0.4033 - val_aux_output_loss: 0.6469\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4332 - main_output_loss: 0.4097 - aux_output_loss: 0.6447 - val_loss: 0.4178 - val_main_output_loss: 0.3961 - val_aux_output_loss: 0.6129\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4433 - main_output_loss: 0.4212 - aux_output_loss: 0.6416 - val_loss: 0.4281 - val_main_output_loss: 0.4058 - val_aux_output_loss: 0.6289\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4229 - main_output_loss: 0.4022 - aux_output_loss: 0.6091 - val_loss: 0.4091 - val_main_output_loss: 0.3907 - val_aux_output_loss: 0.5746\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4154 - main_output_loss: 0.3972 - aux_output_loss: 0.5797 - val_loss: 0.4022 - val_main_output_loss: 0.3851 - val_aux_output_loss: 0.5555\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4073 - main_output_loss: 0.3899 - aux_output_loss: 0.5641 - val_loss: 0.3960 - val_main_output_loss: 0.3800 - val_aux_output_loss: 0.5405\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4047 - main_output_loss: 0.3883 - aux_output_loss: 0.5516 - val_loss: 0.3872 - val_main_output_loss: 0.3719 - val_aux_output_loss: 0.5247\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3953 - main_output_loss: 0.3792 - aux_output_loss: 0.5402 - val_loss: 0.3836 - val_main_output_loss: 0.3693 - val_aux_output_loss: 0.5117\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3916 - main_output_loss: 0.3765 - aux_output_loss: 0.5278 - val_loss: 0.3781 - val_main_output_loss: 0.3640 - val_aux_output_loss: 0.5050\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3830 - main_output_loss: 0.3681 - aux_output_loss: 0.5179 - val_loss: 0.3717 - val_main_output_loss: 0.3580 - val_aux_output_loss: 0.4951\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3786 - main_output_loss: 0.3641 - aux_output_loss: 0.5092 - val_loss: 0.3729 - val_main_output_loss: 0.3598 - val_aux_output_loss: 0.4909\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3769 - main_output_loss: 0.3631 - aux_output_loss: 0.5008 - val_loss: 0.3675 - val_main_output_loss: 0.3545 - val_aux_output_loss: 0.4837\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3713 - main_output_loss: 0.3574 - aux_output_loss: 0.4960 - val_loss: 0.3598 - val_main_output_loss: 0.3473 - val_aux_output_loss: 0.4724\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3689 - main_output_loss: 0.3556 - aux_output_loss: 0.4884 - val_loss: 0.3553 - val_main_output_loss: 0.3431 - val_aux_output_loss: 0.4646\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3647 - main_output_loss: 0.3515 - aux_output_loss: 0.4834 - val_loss: 0.3580 - val_main_output_loss: 0.3464 - val_aux_output_loss: 0.4626\n"
     ]
    }
   ],
   "source": [
    "#Each output has its own loss function, and we need to set the weights, in this case making the main one to get most of it, for the training to focus 90% on improving the main output\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train],\n",
    "    epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5452cba6-1971-4917-95c8-2f977303c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3938 - main_output_loss: 0.3808 - aux_output_loss: 0.5113\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92259de5-e121-4012-b65b-e69465830354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.0335037, 1.7891495, 1.773598 ], dtype=float32),\n",
       " array([1.3626611, 1.7393243, 2.486218 ], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n",
    "y_pred_main.flatten(), y_pred_aux.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4bf54e-7250-4b5c-bbba-1bc41fd153ae",
   "metadata": {},
   "source": [
    "Using the Subclassing API to build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f31ddd25-13e1-40ec-b040-e16471493cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are creating exactly the same model as the last one, but using the subclassing API\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "20e96840-fb1d-459e-bb7f-ef706b326546",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  9/363 [..............................] - ETA: 2s - loss: 5.1271 - output_1_loss: 4.9497 - output_2_loss: 6.7242  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:52:20.660500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - ETA: 0s - loss: 1.0012 - output_1_loss: 0.8842 - output_2_loss: 2.0539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 17:52:23.023356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 3s 7ms/step - loss: 1.0012 - output_1_loss: 0.8842 - output_2_loss: 2.0539 - val_loss: 0.5592 - val_output_1_loss: 0.4985 - val_output_2_loss: 1.1055\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.6144 - output_1_loss: 0.5690 - output_2_loss: 1.0229 - val_loss: 0.8773 - val_output_1_loss: 0.8607 - val_output_2_loss: 1.0271\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.5307 - output_1_loss: 0.4903 - output_2_loss: 0.8944 - val_loss: 0.4793 - val_output_1_loss: 0.4422 - val_output_2_loss: 0.8135\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4826 - output_1_loss: 0.4490 - output_2_loss: 0.7849 - val_loss: 0.4490 - val_output_1_loss: 0.4179 - val_output_2_loss: 0.7289\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4636 - output_1_loss: 0.4355 - output_2_loss: 0.7166 - val_loss: 0.4339 - val_output_1_loss: 0.4076 - val_output_2_loss: 0.6702\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4524 - output_1_loss: 0.4281 - output_2_loss: 0.6708 - val_loss: 0.4205 - val_output_1_loss: 0.3973 - val_output_2_loss: 0.6296\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4356 - output_1_loss: 0.4126 - output_2_loss: 0.6420 - val_loss: 0.4109 - val_output_1_loss: 0.3898 - val_output_2_loss: 0.6009\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4218 - output_1_loss: 0.3997 - output_2_loss: 0.6204 - val_loss: 0.4074 - val_output_1_loss: 0.3880 - val_output_2_loss: 0.5820\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4136 - output_1_loss: 0.3932 - output_2_loss: 0.5976 - val_loss: 0.3920 - val_output_1_loss: 0.3729 - val_output_2_loss: 0.5632\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4051 - output_1_loss: 0.3855 - output_2_loss: 0.5817 - val_loss: 0.3942 - val_output_1_loss: 0.3765 - val_output_2_loss: 0.5542\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3969 - output_1_loss: 0.3777 - output_2_loss: 0.5697 - val_loss: 0.3784 - val_output_1_loss: 0.3610 - val_output_2_loss: 0.5354\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3921 - output_1_loss: 0.3739 - output_2_loss: 0.5560 - val_loss: 0.3761 - val_output_1_loss: 0.3597 - val_output_2_loss: 0.5237\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3875 - output_1_loss: 0.3698 - output_2_loss: 0.5466 - val_loss: 0.3724 - val_output_1_loss: 0.3562 - val_output_2_loss: 0.5186\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3791 - output_1_loss: 0.3619 - output_2_loss: 0.5346 - val_loss: 0.3642 - val_output_1_loss: 0.3487 - val_output_2_loss: 0.5031\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3740 - output_1_loss: 0.3578 - output_2_loss: 0.5201 - val_loss: 0.4221 - val_output_1_loss: 0.4122 - val_output_2_loss: 0.5106\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3844 - output_1_loss: 0.3696 - output_2_loss: 0.5172 - val_loss: 0.3566 - val_output_1_loss: 0.3427 - val_output_2_loss: 0.4816\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3674 - output_1_loss: 0.3530 - output_2_loss: 0.4963 - val_loss: 0.3558 - val_output_1_loss: 0.3419 - val_output_2_loss: 0.4812\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3623 - output_1_loss: 0.3480 - output_2_loss: 0.4906 - val_loss: 0.3517 - val_output_1_loss: 0.3382 - val_output_2_loss: 0.4726\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3578 - output_1_loss: 0.3440 - output_2_loss: 0.4827 - val_loss: 0.3440 - val_output_1_loss: 0.3316 - val_output_2_loss: 0.4557\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3533 - output_1_loss: 0.3396 - output_2_loss: 0.4767 - val_loss: 0.3418 - val_output_1_loss: 0.3291 - val_output_2_loss: 0.4560\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train],\n",
    "    epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b18119d4-2727-4911-8c7b-a0d56379dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_and_deep_model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            multiple                  210       \n",
      "                                                                 \n",
      " dense_47 (Dense)            multiple                  930       \n",
      "                                                                 \n",
      " dense_48 (Dense)            multiple                  36        \n",
      "                                                                 \n",
      " dense_49 (Dense)            multiple                  31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#When we use the summary() with this API, we get a list of layers with no info on how they are connected each other\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c56c1-eb7e-4b0b-8ba7-7bbef8f8e105",
   "metadata": {},
   "source": [
    "Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f1699fe4-1f83-41d5-81fd-dd7608fecd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tensor_logs/run_2022_09_22-18_27_01'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"tensor_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5e152ace-f54d-4ae7-b0ab-ffa1b014a086",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3546 - output_1_loss: 0.3416 - output_2_loss: 0.4716 - val_loss: 0.3406 - val_output_1_loss: 0.3285 - val_output_2_loss: 0.4495\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3475 - output_1_loss: 0.3345 - output_2_loss: 0.4654 - val_loss: 0.3380 - val_output_1_loss: 0.3265 - val_output_2_loss: 0.4416\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3458 - output_1_loss: 0.3329 - output_2_loss: 0.4615 - val_loss: 0.3475 - val_output_1_loss: 0.3369 - val_output_2_loss: 0.4434\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3487 - output_1_loss: 0.3367 - output_2_loss: 0.4565 - val_loss: 0.3349 - val_output_1_loss: 0.3236 - val_output_2_loss: 0.4366\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3435 - output_1_loss: 0.3312 - output_2_loss: 0.4541 - val_loss: 0.3339 - val_output_1_loss: 0.3228 - val_output_2_loss: 0.4337\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3398 - output_1_loss: 0.3278 - output_2_loss: 0.4475 - val_loss: 0.3317 - val_output_1_loss: 0.3211 - val_output_2_loss: 0.4279\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3382 - output_1_loss: 0.3266 - output_2_loss: 0.4429 - val_loss: 0.3377 - val_output_1_loss: 0.3272 - val_output_2_loss: 0.4318\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3379 - output_1_loss: 0.3265 - output_2_loss: 0.4403 - val_loss: 0.3340 - val_output_1_loss: 0.3239 - val_output_2_loss: 0.4250\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3372 - output_1_loss: 0.3261 - output_2_loss: 0.4366 - val_loss: 0.3466 - val_output_1_loss: 0.3369 - val_output_2_loss: 0.4332\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3374 - output_1_loss: 0.3264 - output_2_loss: 0.4365 - val_loss: 0.3273 - val_output_1_loss: 0.3174 - val_output_2_loss: 0.4157\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3311 - output_1_loss: 0.3201 - output_2_loss: 0.4303 - val_loss: 0.3324 - val_output_1_loss: 0.3229 - val_output_2_loss: 0.4173\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3333 - output_1_loss: 0.3222 - output_2_loss: 0.4332 - val_loss: 0.3261 - val_output_1_loss: 0.3167 - val_output_2_loss: 0.4101\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3345 - output_1_loss: 0.3239 - output_2_loss: 0.4296 - val_loss: 0.3271 - val_output_1_loss: 0.3178 - val_output_2_loss: 0.4108\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3293 - output_1_loss: 0.3187 - output_2_loss: 0.4245 - val_loss: 0.3270 - val_output_1_loss: 0.3181 - val_output_2_loss: 0.4071\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3292 - output_1_loss: 0.3190 - output_2_loss: 0.4214 - val_loss: 0.3318 - val_output_1_loss: 0.3233 - val_output_2_loss: 0.4088\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3303 - output_1_loss: 0.3203 - output_2_loss: 0.4204 - val_loss: 0.3265 - val_output_1_loss: 0.3175 - val_output_2_loss: 0.4075\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3273 - output_1_loss: 0.3170 - output_2_loss: 0.4205 - val_loss: 0.3240 - val_output_1_loss: 0.3152 - val_output_2_loss: 0.4036\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3300 - output_1_loss: 0.3202 - output_2_loss: 0.4180 - val_loss: 0.3229 - val_output_1_loss: 0.3141 - val_output_2_loss: 0.4023\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3263 - output_1_loss: 0.3161 - output_2_loss: 0.4177 - val_loss: 0.3237 - val_output_1_loss: 0.3152 - val_output_2_loss: 0.4006\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3259 - output_1_loss: 0.3162 - output_2_loss: 0.4132 - val_loss: 0.3265 - val_output_1_loss: 0.3180 - val_output_2_loss: 0.4035\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train],\n",
    "    epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "    callbacks=[tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaca0e-8871-4db5-b2d5-149032361772",
   "metadata": {},
   "source": [
    "Fine-Tunning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a372a922-a695-4925-bfa1-b9e657e30e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "00f64ab3-ea3d-43f9-aaf3-3a409ff1f6f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/ylwcs9v50t1f3njdc2mw2wtm0000gn/T/ipykernel_20230/3945072513.py:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
      "/Users/amqo/Develop/ML/miniconda3/envs/handsOnTensorflow/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2022-09-27 14:40:55.168824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/363 [============================>.] - ETA: 0s - loss: 1.2060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:40:56.463236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 4ms/step - loss: 1.1991 - val_loss: 0.7762\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7107 - val_loss: 0.6712\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6297 - val_loss: 0.5939\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5695 - val_loss: 0.5406\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5296 - val_loss: 0.5071\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5014 - val_loss: 0.4840\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4797 - val_loss: 0.4646\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4656 - val_loss: 0.4539\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4571 - val_loss: 0.4456\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4466 - val_loss: 0.4364\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4425 - val_loss: 0.4313\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4374 - val_loss: 0.4246\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4292 - val_loss: 0.4204\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4250 - val_loss: 0.4160\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4218 - val_loss: 0.4130\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4173 - val_loss: 0.4098\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4131 - val_loss: 0.4048\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4097 - val_loss: 0.4030\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4001\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.3969\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4061 - val_loss: 0.3951\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4021 - val_loss: 0.3928\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3989 - val_loss: 0.3906\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3955 - val_loss: 0.3883\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3942 - val_loss: 0.3879\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3932 - val_loss: 0.3851\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3901 - val_loss: 0.3833\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3886 - val_loss: 0.3847\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3889 - val_loss: 0.3809\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3882 - val_loss: 0.3800\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3851 - val_loss: 0.3786\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3845 - val_loss: 0.3772\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3852 - val_loss: 0.3759\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3847 - val_loss: 0.3755\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3831 - val_loss: 0.3738\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3795 - val_loss: 0.3726\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3784 - val_loss: 0.3723\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3786 - val_loss: 0.3706\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3778 - val_loss: 0.3691\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3737 - val_loss: 0.3688\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3750 - val_loss: 0.3678\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3723 - val_loss: 0.3662\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3708 - val_loss: 0.3656\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3698 - val_loss: 0.3653\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3688 - val_loss: 0.3645\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3677 - val_loss: 0.3637\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3689 - val_loss: 0.3628\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3678 - val_loss: 0.3622\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3671 - val_loss: 0.3604\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3653 - val_loss: 0.3618\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3650 - val_loss: 0.3591\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3644 - val_loss: 0.3590\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3635 - val_loss: 0.3591\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3619 - val_loss: 0.3590\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3621 - val_loss: 0.3562\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3601 - val_loss: 0.3566\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3599 - val_loss: 0.3556\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3596 - val_loss: 0.3561\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3599 - val_loss: 0.3547\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3587 - val_loss: 0.3536\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3576 - val_loss: 0.3531\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3561 - val_loss: 0.3524\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3559 - val_loss: 0.3514\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.3528\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3560 - val_loss: 0.3509\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.3500\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3540 - val_loss: 0.3506\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3525 - val_loss: 0.3500\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3522 - val_loss: 0.3513\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3520 - val_loss: 0.3481\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.3491\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3514 - val_loss: 0.3467\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3506 - val_loss: 0.3474\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3512 - val_loss: 0.3457\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3486 - val_loss: 0.3454\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3483 - val_loss: 0.3497\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3492 - val_loss: 0.3443\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3493 - val_loss: 0.3442\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3468 - val_loss: 0.3434\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3461 - val_loss: 0.3429\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3465 - val_loss: 0.3429\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3450 - val_loss: 0.3421\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3456 - val_loss: 0.3434\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3476 - val_loss: 0.3408\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3450 - val_loss: 0.3422\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3435 - val_loss: 0.3412\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3441 - val_loss: 0.3426\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3443 - val_loss: 0.3397\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3431 - val_loss: 0.3396\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3433 - val_loss: 0.3393\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3431 - val_loss: 0.3376\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3404 - val_loss: 0.3380\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3400 - val_loss: 0.3366\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3398 - val_loss: 0.3405\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3419 - val_loss: 0.3366\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3385 - val_loss: 0.3362\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3387 - val_loss: 0.3363\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3381 - val_loss: 0.3353\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3378 - val_loss: 0.3351\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3396 - val_loss: 0.3353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x318df84c0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create noe a KerasRegressor based on this function\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5346b4cf-be29-4051-8266-dadc19ee1e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.3588\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "939a00cb-0099-4d4a-960c-0a921e26388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x321f25d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:44:55.005153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e4b8071a-3946-4fa9-abb1-d3c841ef3e1f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amqo/Develop/ML/miniconda3/envs/handsOnTensorflow/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2022-09-27 16:02:44.836118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/242 [============================>.] - ETA: 0s - loss: 2.9357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:02:45.919327: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 2.9243 - val_loss: 1.7639\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.6042 - val_loss: 1.2369\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.1425 - val_loss: 1.0051\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9427 - val_loss: 0.8833\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8420 - val_loss: 0.8111\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7819 - val_loss: 0.7627\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7405 - val_loss: 0.7277\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7095 - val_loss: 0.7006\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6844 - val_loss: 0.6785\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6640 - val_loss: 0.6617\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6463 - val_loss: 0.6451\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6314 - val_loss: 0.6318\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6180 - val_loss: 0.6208\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6062 - val_loss: 0.6101\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5953 - val_loss: 0.5995\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5860 - val_loss: 0.5913\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5771 - val_loss: 0.5846\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5693 - val_loss: 0.5761\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5620 - val_loss: 0.5691\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5555 - val_loss: 0.5634\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5491 - val_loss: 0.5566\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5436 - val_loss: 0.5524\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5383 - val_loss: 0.5469\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5332 - val_loss: 0.5417\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5285 - val_loss: 0.5374\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5236 - val_loss: 0.5333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5196 - val_loss: 0.5283\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5156 - val_loss: 0.5253\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5120 - val_loss: 0.5214\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5084 - val_loss: 0.5179\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5049 - val_loss: 0.5145\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5016 - val_loss: 0.5110\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4985 - val_loss: 0.5082\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4951 - val_loss: 0.5051\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4925 - val_loss: 0.5018\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4900 - val_loss: 0.4991\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4871 - val_loss: 0.4977\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4845 - val_loss: 0.4941\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4821 - val_loss: 0.4920\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4796 - val_loss: 0.4897\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4775 - val_loss: 0.4875\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4752 - val_loss: 0.4853\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4732 - val_loss: 0.4830\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4709 - val_loss: 0.4806\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4689 - val_loss: 0.4787\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4668 - val_loss: 0.4765\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4647 - val_loss: 0.4751\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4628 - val_loss: 0.4725\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4612 - val_loss: 0.4706\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4591 - val_loss: 0.4687\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4578 - val_loss: 0.4671\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4558 - val_loss: 0.4652\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4540 - val_loss: 0.4635\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4521 - val_loss: 0.4634\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4508 - val_loss: 0.4603\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4489 - val_loss: 0.4595\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4477 - val_loss: 0.4577\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4458 - val_loss: 0.4556\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4445 - val_loss: 0.4539\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4428 - val_loss: 0.4529\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4417 - val_loss: 0.4515\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4400 - val_loss: 0.4495\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4388 - val_loss: 0.4485\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4373 - val_loss: 0.4475\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4360 - val_loss: 0.4454\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4345 - val_loss: 0.4455\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4335 - val_loss: 0.4431\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4322 - val_loss: 0.4413\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4310 - val_loss: 0.4400\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4298 - val_loss: 0.4388\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4286 - val_loss: 0.4378\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4274 - val_loss: 0.4368\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4262 - val_loss: 0.4356\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4250 - val_loss: 0.4342\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4240 - val_loss: 0.4333\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4227 - val_loss: 0.4321\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4217 - val_loss: 0.4310\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4204 - val_loss: 0.4309\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4196 - val_loss: 0.4289\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4188 - val_loss: 0.4281\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4178 - val_loss: 0.4269\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4168 - val_loss: 0.4259\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4157 - val_loss: 0.4259\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4149 - val_loss: 0.4244\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4141 - val_loss: 0.4229\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4132 - val_loss: 0.4221\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4122 - val_loss: 0.4220\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4114 - val_loss: 0.4216\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4105 - val_loss: 0.4199\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4095 - val_loss: 0.4189\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4088 - val_loss: 0.4178\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4079 - val_loss: 0.4172\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4072 - val_loss: 0.4164\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4061 - val_loss: 0.4160\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4056 - val_loss: 0.4144\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4045 - val_loss: 0.4137\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4040 - val_loss: 0.4131\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4032 - val_loss: 0.4127\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4025 - val_loss: 0.4117\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4016 - val_loss: 0.4106\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4380\n",
      "Epoch 1/100\n",
      " 29/242 [==>...........................] - ETA: 0s - loss: 4.7731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:04:40.944183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/242 [============================>.] - ETA: 0s - loss: 3.2354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:04:41.928343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 3.1885 - val_loss: 2.0246\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.6591 - val_loss: 1.3173\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.1578 - val_loss: 0.9636\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8866 - val_loss: 0.7716\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7514 - val_loss: 0.6839\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6920 - val_loss: 0.6445\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6629 - val_loss: 0.6237\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6434 - val_loss: 0.6081\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6290 - val_loss: 0.5963\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6162 - val_loss: 0.5859\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6051 - val_loss: 0.5761\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5951 - val_loss: 0.5672\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5860 - val_loss: 0.5597\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5775 - val_loss: 0.5518\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5699 - val_loss: 0.5449\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5628 - val_loss: 0.5383\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5563 - val_loss: 0.5325\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5500 - val_loss: 0.5268\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5440 - val_loss: 0.5214\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5386 - val_loss: 0.5163\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5334 - val_loss: 0.5115\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5283 - val_loss: 0.5065\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5237 - val_loss: 0.5021\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5191 - val_loss: 0.4980\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5149 - val_loss: 0.4943\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5107 - val_loss: 0.4901\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5068 - val_loss: 0.4864\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5030 - val_loss: 0.4832\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4994 - val_loss: 0.4801\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4960 - val_loss: 0.4766\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4927 - val_loss: 0.4733\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4895 - val_loss: 0.4703\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4864 - val_loss: 0.4675\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4835 - val_loss: 0.4646\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4808 - val_loss: 0.4620\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4779 - val_loss: 0.4594\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4753 - val_loss: 0.4569\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4727 - val_loss: 0.4548\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4701 - val_loss: 0.4524\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4679 - val_loss: 0.4501\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4655 - val_loss: 0.4481\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4632 - val_loss: 0.4458\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4611 - val_loss: 0.4439\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4590 - val_loss: 0.4419\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4568 - val_loss: 0.4403\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4550 - val_loss: 0.4383\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4529 - val_loss: 0.4365\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4510 - val_loss: 0.4347\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4492 - val_loss: 0.4328\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4473 - val_loss: 0.4310\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4455 - val_loss: 0.4294\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4437 - val_loss: 0.4278\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4419 - val_loss: 0.4265\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4403 - val_loss: 0.4246\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4387 - val_loss: 0.4230\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4370 - val_loss: 0.4215\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4355 - val_loss: 0.4200\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4338 - val_loss: 0.4185\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4323 - val_loss: 0.4172\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4309 - val_loss: 0.4156\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4294 - val_loss: 0.4143\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4279 - val_loss: 0.4131\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4268 - val_loss: 0.4118\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4254 - val_loss: 0.4108\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4241 - val_loss: 0.4095\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4228 - val_loss: 0.4083\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4214 - val_loss: 0.4071\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4204 - val_loss: 0.4060\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4191 - val_loss: 0.4051\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4180 - val_loss: 0.4039\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4168 - val_loss: 0.4029\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4158 - val_loss: 0.4018\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4146 - val_loss: 0.4008\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4135 - val_loss: 0.3997\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4125 - val_loss: 0.3988\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4113 - val_loss: 0.3979\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4104 - val_loss: 0.3970\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4093 - val_loss: 0.3961\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4083 - val_loss: 0.3952\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4074 - val_loss: 0.3944\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4064 - val_loss: 0.3937\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4054 - val_loss: 0.3931\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4046 - val_loss: 0.3921\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4036 - val_loss: 0.3913\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4028 - val_loss: 0.3906\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4019 - val_loss: 0.3899\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4009 - val_loss: 0.3892\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4002 - val_loss: 0.3884\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3994 - val_loss: 0.3878\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3986 - val_loss: 0.3871\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3977 - val_loss: 0.3867\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3970 - val_loss: 0.3859\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3963 - val_loss: 0.3853\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3955 - val_loss: 0.3845\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3948 - val_loss: 0.3839\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3939 - val_loss: 0.3836\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3934 - val_loss: 0.3828\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3927 - val_loss: 0.3821\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3920 - val_loss: 0.3815\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3913 - val_loss: 0.3809\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3673\n",
      "Epoch 1/100\n",
      " 30/242 [==>...........................] - ETA: 0s - loss: 3.8028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:06:35.647853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/242 [============================>.] - ETA: 0s - loss: 2.6066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:06:36.623697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 2.5947 - val_loss: 1.5495\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.2749 - val_loss: 1.0536\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9618 - val_loss: 0.8859\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8293 - val_loss: 0.8066\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7662 - val_loss: 0.7630\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7299 - val_loss: 0.7339\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7040 - val_loss: 0.7111\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6831 - val_loss: 0.6919\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6651 - val_loss: 0.6744\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6488 - val_loss: 0.6596\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6347 - val_loss: 0.6447\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6214 - val_loss: 0.6318\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6095 - val_loss: 0.6199\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5986 - val_loss: 0.6090\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5885 - val_loss: 0.5991\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5794 - val_loss: 0.5895\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5707 - val_loss: 0.5809\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5630 - val_loss: 0.5735\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5559 - val_loss: 0.5659\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5491 - val_loss: 0.5590\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5429 - val_loss: 0.5526\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5371 - val_loss: 0.5465\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5317 - val_loss: 0.5408\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5265 - val_loss: 0.5359\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5217 - val_loss: 0.5307\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5171 - val_loss: 0.5262\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5125 - val_loss: 0.5215\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5082 - val_loss: 0.5173\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5042 - val_loss: 0.5132\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5005 - val_loss: 0.5098\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4967 - val_loss: 0.5057\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4933 - val_loss: 0.5019\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4900 - val_loss: 0.4986\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4869 - val_loss: 0.4956\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4839 - val_loss: 0.4928\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4809 - val_loss: 0.4895\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4780 - val_loss: 0.4866\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4755 - val_loss: 0.4840\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4728 - val_loss: 0.4813\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4703 - val_loss: 0.4787\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4679 - val_loss: 0.4762\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4657 - val_loss: 0.4742\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4632 - val_loss: 0.4714\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4609 - val_loss: 0.4692\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4591 - val_loss: 0.4676\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4568 - val_loss: 0.4654\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4548 - val_loss: 0.4631\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4530 - val_loss: 0.4609\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4510 - val_loss: 0.4589\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4492 - val_loss: 0.4575\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4475 - val_loss: 0.4557\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4458 - val_loss: 0.4536\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4441 - val_loss: 0.4518\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4423 - val_loss: 0.4500\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4408 - val_loss: 0.4483\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4388 - val_loss: 0.4461\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4376 - val_loss: 0.4448\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4360 - val_loss: 0.4435\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4346 - val_loss: 0.4418\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4330 - val_loss: 0.4402\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4317 - val_loss: 0.4387\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4302 - val_loss: 0.4372\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4290 - val_loss: 0.4358\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4276 - val_loss: 0.4347\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4260 - val_loss: 0.4334\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4251 - val_loss: 0.4317\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4236 - val_loss: 0.4299\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4228 - val_loss: 0.4289\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4214 - val_loss: 0.4278\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4205 - val_loss: 0.4267\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4193 - val_loss: 0.4257\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4182 - val_loss: 0.4246\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4168 - val_loss: 0.4229\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4158 - val_loss: 0.4218\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4142 - val_loss: 0.4204\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4135 - val_loss: 0.4191\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4124 - val_loss: 0.4182\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4112 - val_loss: 0.4169\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4100 - val_loss: 0.4155\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4089 - val_loss: 0.4147\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4080 - val_loss: 0.4133\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4070 - val_loss: 0.4124\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4059 - val_loss: 0.4113\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4048 - val_loss: 0.4106\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4041 - val_loss: 0.4093\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4031 - val_loss: 0.4083\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4022 - val_loss: 0.4077\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4013 - val_loss: 0.4063\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4005 - val_loss: 0.4059\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3995 - val_loss: 0.4045\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3988 - val_loss: 0.4039\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3980 - val_loss: 0.4030\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3971 - val_loss: 0.4021\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3963 - val_loss: 0.4010\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3953 - val_loss: 0.4008\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3948 - val_loss: 0.3993\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3940 - val_loss: 0.3991\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3933 - val_loss: 0.3979\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3925 - val_loss: 0.3971\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3917 - val_loss: 0.3963\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4072\n",
      "Epoch 1/100\n",
      " 28/242 [==>...........................] - ETA: 0s - loss: 2.6397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:08:29.706892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.2664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:08:30.717857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.2664 - val_loss: 0.8446\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7721 - val_loss: 0.7429\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6924 - val_loss: 0.6738\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6381 - val_loss: 0.6247\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5958 - val_loss: 0.5826\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5634 - val_loss: 0.5496\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5327 - val_loss: 0.5261\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5097 - val_loss: 0.5030\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4903 - val_loss: 0.4842\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4758 - val_loss: 0.4731\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4621 - val_loss: 0.4688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4612 - val_loss: 0.4538\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4413 - val_loss: 0.4461\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4343 - val_loss: 0.4400\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4321 - val_loss: 0.4337\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4272 - val_loss: 0.4289\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4221 - val_loss: 0.4259\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4177 - val_loss: 0.4198\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4106 - val_loss: 0.4177\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4099 - val_loss: 0.4149\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4115 - val_loss: 0.4160\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4247 - val_loss: 0.4074\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4070 - val_loss: 0.4061\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3974 - val_loss: 0.4048\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3977 - val_loss: 0.4023\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3931 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3938 - val_loss: 0.3972\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3908 - val_loss: 0.3956\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3872 - val_loss: 0.3963\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3861 - val_loss: 0.3927\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3846 - val_loss: 0.3907\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3835 - val_loss: 0.3901\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3829 - val_loss: 0.3882\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3796 - val_loss: 0.3857\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3780 - val_loss: 0.3870\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3764 - val_loss: 0.3834\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3754 - val_loss: 0.3819\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3739 - val_loss: 0.3810\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3729 - val_loss: 0.3806\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3719 - val_loss: 0.3793\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3712 - val_loss: 0.3771\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3720 - val_loss: 0.3763\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3693 - val_loss: 0.3759\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3684 - val_loss: 0.3746\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3732 - val_loss: 0.3746\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3698 - val_loss: 0.3728\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3661 - val_loss: 0.3711\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3645 - val_loss: 0.3723\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3641 - val_loss: 0.3691\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3624 - val_loss: 0.3680\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3624 - val_loss: 0.3683\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3671\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3623 - val_loss: 0.3671\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3598 - val_loss: 0.3670\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3582 - val_loss: 0.3658\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3587 - val_loss: 0.3655\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3574 - val_loss: 0.3636\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3613 - val_loss: 0.3639\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3561 - val_loss: 0.3643\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3575 - val_loss: 0.3623\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3577 - val_loss: 0.3621\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3542 - val_loss: 0.3604\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3529 - val_loss: 0.3594\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3534 - val_loss: 0.3614\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3525 - val_loss: 0.3588\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3519 - val_loss: 0.3575\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3537 - val_loss: 0.3587\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3511 - val_loss: 0.3583\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3496 - val_loss: 0.3588\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3527 - val_loss: 0.3588\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3596 - val_loss: 0.3572\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3545 - val_loss: 0.3547\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3496 - val_loss: 0.3530\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3457 - val_loss: 0.3540\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3480 - val_loss: 0.3552\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3491 - val_loss: 0.3542\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3444 - val_loss: 0.3545\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3473 - val_loss: 0.3524\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3468 - val_loss: 0.3512\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3455 - val_loss: 0.3503\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3443 - val_loss: 0.3539\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3442 - val_loss: 0.3519\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3406 - val_loss: 0.3497\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3420 - val_loss: 0.3491\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3420 - val_loss: 0.3498\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3400 - val_loss: 0.3486\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3401 - val_loss: 0.3473\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3405 - val_loss: 0.3478\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3381 - val_loss: 0.3459\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3359 - val_loss: 0.3481\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3364 - val_loss: 0.3449\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3397 - val_loss: 0.3458\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3393 - val_loss: 0.3480\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3380 - val_loss: 0.3436\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3342 - val_loss: 0.3429\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3359 - val_loss: 0.3440\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3335 - val_loss: 0.3420\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3406 - val_loss: 0.3426\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3332 - val_loss: 0.3418\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3327 - val_loss: 0.3406\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3676\n",
      "Epoch 1/100\n",
      " 28/242 [==>...........................] - ETA: 0s - loss: 3.9536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:10:23.706537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.4198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:10:24.699521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.4198 - val_loss: 0.8235\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8469 - val_loss: 0.6742\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6810 - val_loss: 0.6134\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6183 - val_loss: 0.5756\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5839 - val_loss: 0.5452\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5576 - val_loss: 0.5248\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5356 - val_loss: 0.5058\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5189 - val_loss: 0.4903\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5037 - val_loss: 0.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4919 - val_loss: 0.4700\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4820 - val_loss: 0.4608\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4731 - val_loss: 0.4543\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4664 - val_loss: 0.4509\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4596 - val_loss: 0.4405\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4539 - val_loss: 0.4348\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4486 - val_loss: 0.4300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4431 - val_loss: 0.4246\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4385 - val_loss: 0.4216\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4338 - val_loss: 0.4159\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4296 - val_loss: 0.4114\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4259 - val_loss: 0.4074\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4213 - val_loss: 0.4053\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4189 - val_loss: 0.4023\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4146 - val_loss: 0.3982\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4126 - val_loss: 0.3947\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4093 - val_loss: 0.3925\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4075 - val_loss: 0.3912\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4047 - val_loss: 0.3870\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4021 - val_loss: 0.3857\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3992 - val_loss: 0.3833\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3974 - val_loss: 0.3808\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3952 - val_loss: 0.3785\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3934 - val_loss: 0.3766\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3921 - val_loss: 0.3766\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3896 - val_loss: 0.3741\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3892 - val_loss: 0.3720\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3877 - val_loss: 0.3703\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3853 - val_loss: 0.3694\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3846 - val_loss: 0.3681\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3825 - val_loss: 0.3684\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3821 - val_loss: 0.3659\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3801 - val_loss: 0.3648\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3791 - val_loss: 0.3631\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3775 - val_loss: 0.3633\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3778 - val_loss: 0.3614\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3774 - val_loss: 0.3629\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3792 - val_loss: 0.3618\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3781 - val_loss: 0.3813\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3839 - val_loss: 0.3709\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3874 - val_loss: 0.3612\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3946 - val_loss: 0.3584\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3878 - val_loss: 0.3605\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3809 - val_loss: 0.3567\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3736 - val_loss: 0.3582\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3702 - val_loss: 0.3543\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3665 - val_loss: 0.3558\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3646 - val_loss: 0.3539\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3631 - val_loss: 0.3527\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3618 - val_loss: 0.3551\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3518\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3595 - val_loss: 0.3523\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3593 - val_loss: 0.3507\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3584 - val_loss: 0.3491\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3577 - val_loss: 0.3504\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3568 - val_loss: 0.3481\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3555 - val_loss: 0.3513\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3552 - val_loss: 0.3472\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3545 - val_loss: 0.3462\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3535 - val_loss: 0.3460\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3532 - val_loss: 0.3449\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3520 - val_loss: 0.3438\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3515 - val_loss: 0.3452\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3511 - val_loss: 0.3443\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3507 - val_loss: 0.3439\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3494 - val_loss: 0.3440\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3494 - val_loss: 0.3422\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3485 - val_loss: 0.3438\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3490 - val_loss: 0.3434\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3472 - val_loss: 0.3416\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.3431\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3463 - val_loss: 0.3391\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3463 - val_loss: 0.3409\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3456 - val_loss: 0.3381\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.3407\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3477 - val_loss: 0.3378\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3505 - val_loss: 0.3395\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3529 - val_loss: 0.3362\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3552 - val_loss: 0.3460\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3576 - val_loss: 0.3355\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3567 - val_loss: 0.3373\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3560 - val_loss: 0.3351\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3544 - val_loss: 0.3377\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3493 - val_loss: 0.3368\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3465 - val_loss: 0.3346\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3434 - val_loss: 0.3497\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3416 - val_loss: 0.3339\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3397 - val_loss: 0.3332\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3382 - val_loss: 0.3344\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3369 - val_loss: 0.3357\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3362 - val_loss: 0.3334\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3288\n",
      "Epoch 1/100\n",
      " 29/242 [==>...........................] - ETA: 0s - loss: 5.4212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:12:17.482212: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.9723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:12:18.484671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.9723 - val_loss: 0.8637\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7636 - val_loss: 0.6722\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6312 - val_loss: 0.5799\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5605 - val_loss: 0.5308\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5205 - val_loss: 0.4992\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4955 - val_loss: 0.4806\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4785 - val_loss: 0.4658\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4657 - val_loss: 0.4551\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4559 - val_loss: 0.4464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4477 - val_loss: 0.4403\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4409 - val_loss: 0.4338\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4346 - val_loss: 0.4270\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4295 - val_loss: 0.4224\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4246 - val_loss: 0.4199\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4201 - val_loss: 0.4152\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4166 - val_loss: 0.4129\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4132 - val_loss: 0.4071\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4092 - val_loss: 0.4050\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4056 - val_loss: 0.4009\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4027 - val_loss: 0.3975\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3989 - val_loss: 0.3957\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3969 - val_loss: 0.3926\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3936 - val_loss: 0.3930\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3921 - val_loss: 0.3880\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3894 - val_loss: 0.3861\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3874 - val_loss: 0.3840\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3854 - val_loss: 0.3827\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3829 - val_loss: 0.3812\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3814 - val_loss: 0.3785\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3791 - val_loss: 0.3781\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3777 - val_loss: 0.3760\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3757 - val_loss: 0.3739\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3735 - val_loss: 0.3755\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.3722\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3704 - val_loss: 0.3717\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3696 - val_loss: 0.3695\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3676 - val_loss: 0.3679\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3666 - val_loss: 0.3674\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3653 - val_loss: 0.3665\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3640 - val_loss: 0.3651\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3624 - val_loss: 0.3639\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3615 - val_loss: 0.3646\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3622\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3583 - val_loss: 0.3611\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3577 - val_loss: 0.3603\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3574 - val_loss: 0.3593\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3556 - val_loss: 0.3588\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3545 - val_loss: 0.3571\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3535 - val_loss: 0.3574\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3521 - val_loss: 0.3573\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3512 - val_loss: 0.3550\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3495 - val_loss: 0.3541\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3491 - val_loss: 0.3540\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3482 - val_loss: 0.3534\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3476 - val_loss: 0.3542\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3469 - val_loss: 0.3528\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3461 - val_loss: 0.3511\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3451 - val_loss: 0.3512\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3442 - val_loss: 0.3509\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3434 - val_loss: 0.3487\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3425 - val_loss: 0.3486\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3419 - val_loss: 0.3492\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3411 - val_loss: 0.3474\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3400 - val_loss: 0.3471\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3396 - val_loss: 0.3461\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3390 - val_loss: 0.3455\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3378 - val_loss: 0.3443\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3372 - val_loss: 0.3440\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3363 - val_loss: 0.3449\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3361 - val_loss: 0.3430\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3354 - val_loss: 0.3415\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3345 - val_loss: 0.3413\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3337 - val_loss: 0.3402\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3330 - val_loss: 0.3405\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3321 - val_loss: 0.3412\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3315 - val_loss: 0.3396\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3308 - val_loss: 0.3387\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3298 - val_loss: 0.3404\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3295 - val_loss: 0.3388\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3296 - val_loss: 0.3377\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3294 - val_loss: 0.3364\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3286 - val_loss: 0.3378\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3287 - val_loss: 0.3370\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3290 - val_loss: 0.3394\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3311 - val_loss: 0.3354\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3348 - val_loss: 0.3360\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3355 - val_loss: 0.3363\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3401 - val_loss: 0.3353\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3409 - val_loss: 0.3367\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3385 - val_loss: 0.3341\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3327 - val_loss: 0.3355\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3287 - val_loss: 0.3335\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3257 - val_loss: 0.3330\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3242 - val_loss: 0.3323\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3233 - val_loss: 0.3322\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3217 - val_loss: 0.3313\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3216 - val_loss: 0.3305\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3205 - val_loss: 0.3310\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3201 - val_loss: 0.3303\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3331\n",
      "Epoch 1/100\n",
      " 33/242 [===>..........................] - ETA: 0s - loss: 3.4400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:14:11.204304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.1983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:14:12.099009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.1983 - val_loss: 0.6154\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 1.5117 - val_loss: 0.6009\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5749 - val_loss: 0.5413\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5245 - val_loss: 0.5031\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4922 - val_loss: 0.4799\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4704 - val_loss: 0.4639\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4548 - val_loss: 0.4507\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4437 - val_loss: 0.4418\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4351 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4275 - val_loss: 0.4285\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4217 - val_loss: 0.4268\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4175\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4105 - val_loss: 0.4140\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4071 - val_loss: 0.4111\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4051\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.4024\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3969 - val_loss: 0.4001\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3942 - val_loss: 0.3989\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3906 - val_loss: 0.3953\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3872 - val_loss: 0.3926\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3856 - val_loss: 0.3917\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3831 - val_loss: 0.3899\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3819 - val_loss: 0.3858\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3808 - val_loss: 0.3841\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3772 - val_loss: 0.3834\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3761 - val_loss: 0.3806\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3738 - val_loss: 0.3809\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3722 - val_loss: 0.3795\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3712 - val_loss: 0.3763\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3692 - val_loss: 0.3764\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3685 - val_loss: 0.3750\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3672 - val_loss: 0.3732\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3652 - val_loss: 0.3735\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3663 - val_loss: 0.3722\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3640 - val_loss: 0.3724\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3617 - val_loss: 0.3687\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3610 - val_loss: 0.3683\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3617 - val_loss: 0.3706\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3617 - val_loss: 0.3656\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3582 - val_loss: 0.3651\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3575 - val_loss: 0.3656\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3575 - val_loss: 0.3638\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3559 - val_loss: 0.3646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3621 - val_loss: 0.3616\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3535 - val_loss: 0.3619\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3542 - val_loss: 0.3603\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3539 - val_loss: 0.3589\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3509 - val_loss: 0.3617\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3500 - val_loss: 0.3601\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3495 - val_loss: 0.3574\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3530 - val_loss: 0.3565\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3528 - val_loss: 0.3564\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3476 - val_loss: 0.3572\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3476 - val_loss: 0.3543\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3481 - val_loss: 0.3530\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3448 - val_loss: 0.3539\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3444 - val_loss: 0.3556\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3428 - val_loss: 0.3549\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3448 - val_loss: 0.3519\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3456 - val_loss: 0.3508\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3410 - val_loss: 0.3546\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3409 - val_loss: 0.3480\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3398 - val_loss: 0.3533\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3411 - val_loss: 0.3485\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3379 - val_loss: 0.3472\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3378 - val_loss: 0.3462\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3371 - val_loss: 0.3476\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3386 - val_loss: 0.3454\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3378 - val_loss: 0.3449\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3373 - val_loss: 0.3443\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3330 - val_loss: 0.3438\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3345 - val_loss: 0.3429\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3331 - val_loss: 0.3431\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3320 - val_loss: 0.3411\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3314 - val_loss: 0.3395\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3307 - val_loss: 0.3401\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3322 - val_loss: 0.3422\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3308 - val_loss: 0.3565\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3327 - val_loss: 0.3386\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3281 - val_loss: 0.3403\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3277 - val_loss: 0.3374\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3287 - val_loss: 0.3372\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3314 - val_loss: 0.3387\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3258 - val_loss: 0.3358\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3245 - val_loss: 0.3402\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3251 - val_loss: 0.3361\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3300 - val_loss: 0.3349\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3228 - val_loss: 0.3356\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3226 - val_loss: 0.3383\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3239 - val_loss: 0.3322\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3254 - val_loss: 0.3349\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3282 - val_loss: 0.3326\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3245 - val_loss: 0.3331\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3235 - val_loss: 0.3313\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3301 - val_loss: 0.3324\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3189 - val_loss: 0.3290\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3193 - val_loss: 0.3298\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3188 - val_loss: 0.3307\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3199 - val_loss: 0.3307\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3175 - val_loss: 0.3305\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3665\n",
      "Epoch 1/100\n",
      " 27/242 [==>...........................] - ETA: 0s - loss: 3.9276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:16:00.040950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/242 [============================>.] - ETA: 0s - loss: 1.2615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:16:01.075228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.2475 - val_loss: 0.6583\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6885 - val_loss: 0.5976\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6221 - val_loss: 0.5366\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5956 - val_loss: 0.5122\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5408 - val_loss: 0.4839\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5138 - val_loss: 0.4722\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4876 - val_loss: 0.4537\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4729 - val_loss: 0.4453\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4624 - val_loss: 0.4354\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4535 - val_loss: 0.4292\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4464 - val_loss: 0.4210\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4398 - val_loss: 0.4161\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4343 - val_loss: 0.4112\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4300 - val_loss: 0.4059\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4247 - val_loss: 0.4034\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4210 - val_loss: 0.4005\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4171 - val_loss: 0.3951\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4145 - val_loss: 0.3929\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4100 - val_loss: 0.3920\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4075 - val_loss: 0.3865\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4043 - val_loss: 0.3848\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4018 - val_loss: 0.3825\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3994 - val_loss: 0.3796\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3974 - val_loss: 0.3786\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3952 - val_loss: 0.3777\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3939 - val_loss: 0.3747\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3914 - val_loss: 0.3721\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3895 - val_loss: 0.3702\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3884 - val_loss: 0.3682\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3862 - val_loss: 0.3690\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3848 - val_loss: 0.3679\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3823 - val_loss: 0.3649\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3813 - val_loss: 0.3628\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3795 - val_loss: 0.3624\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3781 - val_loss: 0.3613\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3765 - val_loss: 0.3609\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3753 - val_loss: 0.3587\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3741 - val_loss: 0.3585\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3727 - val_loss: 0.3572\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3713 - val_loss: 0.3562\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3698 - val_loss: 0.3548\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3683 - val_loss: 0.3530\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3674 - val_loss: 0.3527\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3681 - val_loss: 0.3519\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3653 - val_loss: 0.3510\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3647 - val_loss: 0.3513\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3635 - val_loss: 0.3483\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3620 - val_loss: 0.3469\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3617 - val_loss: 0.3466\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3629 - val_loss: 0.3486\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3625 - val_loss: 0.3460\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3618 - val_loss: 0.3439\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3627 - val_loss: 0.3441\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3619 - val_loss: 0.3473\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3676 - val_loss: 0.3436\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3747 - val_loss: 0.3422\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3703 - val_loss: 0.3451\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3621 - val_loss: 0.3408\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3562 - val_loss: 0.3412\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3521 - val_loss: 0.3412\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3512 - val_loss: 0.3386\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3495 - val_loss: 0.3387\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3483 - val_loss: 0.3392\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3472 - val_loss: 0.3395\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3481 - val_loss: 0.3368\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3474 - val_loss: 0.3360\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3453 - val_loss: 0.3370\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3447 - val_loss: 0.3353\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3441 - val_loss: 0.3336\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3433 - val_loss: 0.3363\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3432 - val_loss: 0.3333\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3423 - val_loss: 0.3358\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3414 - val_loss: 0.3358\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3408 - val_loss: 0.3325\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3413 - val_loss: 0.3335\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3403 - val_loss: 0.3320\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3405 - val_loss: 0.3314\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3382 - val_loss: 0.3321\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3380 - val_loss: 0.3321\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3389 - val_loss: 0.3299\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3430 - val_loss: 0.3307\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3408 - val_loss: 0.3309\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3396 - val_loss: 0.3295\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3418 - val_loss: 0.3437\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3446 - val_loss: 0.3286\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3525 - val_loss: 0.3329\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3620 - val_loss: 0.3300\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3613 - val_loss: 0.3285\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3387 - val_loss: 0.3409\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3338 - val_loss: 0.3257\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3336 - val_loss: 0.3332\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3333 - val_loss: 0.3250\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3333 - val_loss: 0.3281\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3351 - val_loss: 0.3264\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3312 - val_loss: 0.3272\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3326 - val_loss: 0.3250\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3315 - val_loss: 0.3271\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3315 - val_loss: 0.3245\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3323 - val_loss: 0.3263\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3286 - val_loss: 0.3259\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3187\n",
      "Epoch 1/100\n",
      " 26/242 [==>...........................] - ETA: 0s - loss: 3.5712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:18:09.683295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/242 [============================>.] - ETA: 0s - loss: 1.3414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:18:10.828423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 1.3390 - val_loss: 0.6435\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.2652 - val_loss: 0.6764\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5985 - val_loss: 0.5426\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5203 - val_loss: 0.4969\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4864 - val_loss: 0.4716\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4662 - val_loss: 0.4572\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4536 - val_loss: 0.4462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4431 - val_loss: 0.4352\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4362 - val_loss: 0.4282\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4288 - val_loss: 0.4219\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4229 - val_loss: 0.4164\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4178 - val_loss: 0.4127\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4142 - val_loss: 0.4115\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4103 - val_loss: 0.4063\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4070 - val_loss: 0.4030\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4042 - val_loss: 0.4008\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4024 - val_loss: 0.3972\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3990 - val_loss: 0.3950\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3967 - val_loss: 0.3931\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3949 - val_loss: 0.3902\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3929 - val_loss: 0.3891\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3917 - val_loss: 0.3861\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3899 - val_loss: 0.3851\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3878 - val_loss: 0.3834\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3863 - val_loss: 0.3854\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3851 - val_loss: 0.3822\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3834 - val_loss: 0.3802\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3831 - val_loss: 0.3777\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3824 - val_loss: 0.3777\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3805 - val_loss: 0.3765\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3788 - val_loss: 0.3784\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3784 - val_loss: 0.3752\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3775 - val_loss: 0.3745\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3767 - val_loss: 0.3724\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3752 - val_loss: 0.3729\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3738 - val_loss: 0.3715\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3747 - val_loss: 0.3706\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3735 - val_loss: 0.3695\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3731 - val_loss: 0.3684\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3711 - val_loss: 0.3685\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3711 - val_loss: 0.3707\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3696 - val_loss: 0.3655\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3702 - val_loss: 0.3659\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3686 - val_loss: 0.3651\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3672 - val_loss: 0.3638\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3665 - val_loss: 0.3627\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3663 - val_loss: 0.3647\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3652 - val_loss: 0.3623\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3642 - val_loss: 0.3620\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3646 - val_loss: 0.3600\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3620 - val_loss: 0.3605\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3620 - val_loss: 0.3604\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3616 - val_loss: 0.3592\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3637 - val_loss: 0.3580\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3607 - val_loss: 0.3590\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3597 - val_loss: 0.3573\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3599 - val_loss: 0.3573\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3589 - val_loss: 0.3551\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3578 - val_loss: 0.3588\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3621 - val_loss: 0.3551\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3565 - val_loss: 0.3540\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3567 - val_loss: 0.3538\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3563 - val_loss: 0.3526\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3547 - val_loss: 0.3532\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3549 - val_loss: 0.3521\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3540 - val_loss: 0.3525\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3544 - val_loss: 0.3507\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3531 - val_loss: 0.3500\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3541 - val_loss: 0.3542\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3523 - val_loss: 0.3543\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3533 - val_loss: 0.3493\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3522 - val_loss: 0.3472\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3511 - val_loss: 0.3484\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3499 - val_loss: 0.3466\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3504 - val_loss: 0.3475\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3494 - val_loss: 0.3464\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3493 - val_loss: 0.3455\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3477 - val_loss: 0.3458\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3465 - val_loss: 0.3440\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3472 - val_loss: 0.3444\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3480 - val_loss: 0.3436\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3449 - val_loss: 0.3430\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3448 - val_loss: 0.3425\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3451 - val_loss: 0.3417\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3445 - val_loss: 0.3428\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3446 - val_loss: 0.3411\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3429 - val_loss: 0.3431\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3426 - val_loss: 0.3430\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3425 - val_loss: 0.3390\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3410 - val_loss: 0.3392\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3408 - val_loss: 0.3385\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3425 - val_loss: 0.3384\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3403 - val_loss: 0.3376\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3395 - val_loss: 0.3382\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3408 - val_loss: 0.3377\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3376 - val_loss: 0.3369\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3367 - val_loss: 0.3355\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3371 - val_loss: 0.3480\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3437 - val_loss: 0.3361\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3372 - val_loss: 0.3345\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3440\n",
      "Epoch 1/100\n",
      " 28/242 [==>...........................] - ETA: 0s - loss: 4.5288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:20:18.835427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.3381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:20:19.858261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.3381 - val_loss: 0.7293\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 78.2588 - val_loss: 117.2756\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 45403.4102 - val_loss: 58642.9727\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 12668542.0000 - val_loss: 13424494.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 5998683648.0000 - val_loss: 4651012096.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1201148788736.0000 - val_loss: 1594616053760.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 719364206624768.0000 - val_loss: 549249276182528.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 145373527594237952.0000 - val_loss: 187377929791995904.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 97815070089557311488.0000 - val_loss: 64636959275742134272.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 30752769256904462434304.0000 - val_loss: 22332488112801648214016.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 12139313436190302615371776.0000 - val_loss: 7679506379250793090908160.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 2615456908741725038575616.0000\n",
      "Epoch 1/100\n",
      " 27/242 [==>...........................] - ETA: 0s - loss: 4.0244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:20:32.868436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/242 [============================>.] - ETA: 0s - loss: 1.4421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:20:33.965916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 1.4197 - val_loss: 0.7714\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.7659 - val_loss: 1.3117\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 18.2088 - val_loss: 12.0829\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 172.2676 - val_loss: 111.2951\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1761.1257 - val_loss: 1210.5555\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15759.7412 - val_loss: 12746.1836\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 214716.7969 - val_loss: 133544.3906\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1715087.8750 - val_loss: 1468429.7500\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 23540496.0000 - val_loss: 14980036.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 195657872.0000 - val_loss: 163162784.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1841555328.0000 - val_loss: 2083926912.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 69017567232.0000\n",
      "Epoch 1/100\n",
      " 28/242 [==>...........................] - ETA: 0s - loss: 2.8217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:20:46.809975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.1630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:20:47.818206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.1630 - val_loss: 0.8959\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 4.1338 - val_loss: 4.7746\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 115.4407 - val_loss: 129.2024\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 3545.5688 - val_loss: 3250.5125\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 62097.4922 - val_loss: 86037.2266\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1841707.3750 - val_loss: 2203110.2500\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 44350268.0000 - val_loss: 57352096.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1629117952.0000 - val_loss: 1479502336.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 39434452992.0000 - val_loss: 38428344320.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 882103549952.0000 - val_loss: 1000239595520.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 19410158878720.0000 - val_loss: 26017913634816.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 737706938204160.0000\n",
      "Epoch 1/100\n",
      " 26/242 [==>...........................] - ETA: 0s - loss: 5.5801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:21:00.619521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 2.9007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:21:01.721628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 2.9007 - val_loss: 1.0303\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7629 - val_loss: 0.6002\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5839 - val_loss: 0.5507\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5594 - val_loss: 0.5396\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5499 - val_loss: 0.5335\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5437 - val_loss: 0.5292\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5382 - val_loss: 0.5257\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5338 - val_loss: 0.5232\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5302 - val_loss: 0.5201\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5275 - val_loss: 0.5168\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5259 - val_loss: 0.5165\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5234 - val_loss: 0.5146\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5214 - val_loss: 0.5141\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5204 - val_loss: 0.5129\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5194 - val_loss: 0.5124\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5185 - val_loss: 0.5119\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5174 - val_loss: 0.5107\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5175 - val_loss: 0.5108\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5159 - val_loss: 0.5106\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5157 - val_loss: 0.5100\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5157 - val_loss: 0.5101\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5156 - val_loss: 0.5099\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5154 - val_loss: 0.5106\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5151 - val_loss: 0.5099\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5145 - val_loss: 0.5106\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5147 - val_loss: 0.5098\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5145 - val_loss: 0.5099\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5140 - val_loss: 0.5108\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5135 - val_loss: 0.5095\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5139 - val_loss: 0.5102\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5142 - val_loss: 0.5105\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5137 - val_loss: 0.5101\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5145 - val_loss: 0.5107\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5145 - val_loss: 0.5097\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5143 - val_loss: 0.5097\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5142 - val_loss: 0.5100\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5135 - val_loss: 0.5107\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5137 - val_loss: 0.5106\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5132 - val_loss: 0.5098\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.5483\n",
      "Epoch 1/100\n",
      " 30/242 [==>...........................] - ETA: 0s - loss: 4.8070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:21:46.082793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 2.4395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:21:47.031684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 2.4395 - val_loss: 0.9312\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7599 - val_loss: 0.6014\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6215 - val_loss: 0.5661\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5988 - val_loss: 0.5530\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5895 - val_loss: 0.5468\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5801 - val_loss: 0.5387\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5738 - val_loss: 0.5334\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5686 - val_loss: 0.5292\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5634 - val_loss: 0.5253\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5601 - val_loss: 0.5227\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5564 - val_loss: 0.5197\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5541 - val_loss: 0.5179\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5512 - val_loss: 0.5157\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5502 - val_loss: 0.5150\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5486 - val_loss: 0.5147\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5470 - val_loss: 0.5136\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5460 - val_loss: 0.5125\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5451 - val_loss: 0.5121\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5444 - val_loss: 0.5111\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5440 - val_loss: 0.5117\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5434 - val_loss: 0.5109\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5428 - val_loss: 0.5107\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5421 - val_loss: 0.5101\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5426 - val_loss: 0.5094\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5424 - val_loss: 0.5102\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5420 - val_loss: 0.5103\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5416 - val_loss: 0.5104\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5413 - val_loss: 0.5096\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5413 - val_loss: 0.5091\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5416 - val_loss: 0.5103\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5408 - val_loss: 0.5094\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5413 - val_loss: 0.5091\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5408 - val_loss: 0.5094\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5411 - val_loss: 0.5092\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5412 - val_loss: 0.5099\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5405 - val_loss: 0.5094\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5411 - val_loss: 0.5099\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5407 - val_loss: 0.5092\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5409 - val_loss: 0.5092\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5413 - val_loss: 0.5103\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5410 - val_loss: 0.5103\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5407 - val_loss: 0.5105\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4970\n",
      "Epoch 1/100\n",
      " 31/242 [==>...........................] - ETA: 0s - loss: 7.3686"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:22:31.247618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/242 [============================>.] - ETA: 0s - loss: 3.3469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:22:32.174628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 3.3102 - val_loss: 1.1904\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8807 - val_loss: 0.7150\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6892 - val_loss: 0.6537\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6518 - val_loss: 0.6265\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6308 - val_loss: 0.6082\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6145 - val_loss: 0.5929\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5989 - val_loss: 0.5819\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5901 - val_loss: 0.5707\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5785 - val_loss: 0.5609\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5706 - val_loss: 0.5538\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5613 - val_loss: 0.5457\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5576 - val_loss: 0.5436\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5524 - val_loss: 0.5361\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5483 - val_loss: 0.5327\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5448 - val_loss: 0.5291\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5409 - val_loss: 0.5263\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5394 - val_loss: 0.5246\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5366 - val_loss: 0.5224\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5352 - val_loss: 0.5200\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5316 - val_loss: 0.5190\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5303 - val_loss: 0.5163\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5306 - val_loss: 0.5172\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5301 - val_loss: 0.5154\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5283 - val_loss: 0.5147\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5285 - val_loss: 0.5144\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5282 - val_loss: 0.5135\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5269 - val_loss: 0.5131\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5251 - val_loss: 0.5120\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5260 - val_loss: 0.5120\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5251 - val_loss: 0.5107\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5242 - val_loss: 0.5106\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5247 - val_loss: 0.5103\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5250 - val_loss: 0.5109\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5233 - val_loss: 0.5098\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5247 - val_loss: 0.5107\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5222 - val_loss: 0.5101\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5230 - val_loss: 0.5092\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5220 - val_loss: 0.5111\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5238 - val_loss: 0.5108\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5242 - val_loss: 0.5105\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5225 - val_loss: 0.5085\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5236 - val_loss: 0.5097\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5222 - val_loss: 0.5086\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5226 - val_loss: 0.5083\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5230 - val_loss: 0.5086\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5223 - val_loss: 0.5094\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5237 - val_loss: 0.5086\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5241 - val_loss: 0.5101\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5222 - val_loss: 0.5086\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5220 - val_loss: 0.5095\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5227 - val_loss: 0.5097\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5223 - val_loss: 0.5099\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5212 - val_loss: 0.5080\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5090\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5221 - val_loss: 0.5095\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5228 - val_loss: 0.5091\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5210 - val_loss: 0.5084\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5235 - val_loss: 0.5098\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5227 - val_loss: 0.5093\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5228 - val_loss: 0.5093\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5220 - val_loss: 0.5085\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5225 - val_loss: 0.5079\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5089\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5218 - val_loss: 0.5092\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5226 - val_loss: 0.5093\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5225 - val_loss: 0.5094\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5216 - val_loss: 0.5080\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5081\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5228 - val_loss: 0.5092\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5221 - val_loss: 0.5083\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5086\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5223 - val_loss: 0.5091\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.5327\n",
      "Epoch 1/100\n",
      " 11/242 [>.............................] - ETA: 1s - loss: 5.6338  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:23:47.730073: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 0.9772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:23:49.055113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 0.9772 - val_loss: 0.5337\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7728 - val_loss: 0.5248\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4742 - val_loss: 0.4719\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4361 - val_loss: 0.4283\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4143 - val_loss: 0.4175\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3998 - val_loss: 0.3930\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3878 - val_loss: 0.3816\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3782 - val_loss: 0.3741\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3691 - val_loss: 0.3785\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3638 - val_loss: 0.3609\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3563 - val_loss: 0.3547\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3514 - val_loss: 0.3541\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3468 - val_loss: 0.3607\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3408 - val_loss: 0.3567\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3390 - val_loss: 0.3587\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3331 - val_loss: 0.3502\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3310 - val_loss: 0.3540\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3247 - val_loss: 0.3468\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3298 - val_loss: 0.3290\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3227 - val_loss: 0.3500\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3152 - val_loss: 0.3387\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3141 - val_loss: 0.3256\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3123 - val_loss: 0.3234\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3094 - val_loss: 0.3255\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3066 - val_loss: 0.3218\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3071 - val_loss: 0.3179\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3058 - val_loss: 0.3249\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3047 - val_loss: 0.3486\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3021 - val_loss: 0.3146\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3013 - val_loss: 0.3188\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3019 - val_loss: 0.3268\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2979 - val_loss: 0.3243\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2973 - val_loss: 0.3530\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2988 - val_loss: 0.3169\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2959 - val_loss: 0.3207\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2950 - val_loss: 0.3109\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2942 - val_loss: 0.3077\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2916 - val_loss: 0.3130\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2933 - val_loss: 0.3075\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2914 - val_loss: 0.3209\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2916 - val_loss: 0.3021\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2881 - val_loss: 0.3067\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2899 - val_loss: 0.3051\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2878 - val_loss: 0.3087\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2893 - val_loss: 0.3108\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2868 - val_loss: 0.3085\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2863 - val_loss: 0.3034\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2857 - val_loss: 0.3063\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2846 - val_loss: 0.3041\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2845 - val_loss: 0.3003\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2832 - val_loss: 0.3070\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2825 - val_loss: 0.3164\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2857 - val_loss: 0.3010\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2833 - val_loss: 0.3086\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2824 - val_loss: 0.3035\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2816 - val_loss: 0.3102\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2814 - val_loss: 0.2995\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2809 - val_loss: 0.2975\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2809 - val_loss: 0.2982\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2805 - val_loss: 0.3018\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2792 - val_loss: 0.3067\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2796 - val_loss: 0.2983\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2790 - val_loss: 0.3091\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2792 - val_loss: 0.3096\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2791 - val_loss: 0.2983\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2773 - val_loss: 0.3141\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2769 - val_loss: 0.3010\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2765 - val_loss: 0.3086\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3385\n",
      "Epoch 1/100\n",
      " 22/242 [=>............................] - ETA: 1s - loss: 2.0188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:25:23.685713: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 0.7442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:25:24.975688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7442 - val_loss: 0.5497\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5077 - val_loss: 0.4686\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4703 - val_loss: 0.4382\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4453 - val_loss: 0.4278\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4292 - val_loss: 0.4028\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4172 - val_loss: 0.3878\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4060 - val_loss: 0.4112\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3974 - val_loss: 0.3772\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3913 - val_loss: 0.3845\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3838 - val_loss: 0.3797\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3803 - val_loss: 0.3633\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3732 - val_loss: 0.3664\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3730 - val_loss: 0.3598\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3661 - val_loss: 0.3515\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3655 - val_loss: 0.3605\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3614 - val_loss: 0.3483\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3558 - val_loss: 0.3520\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3528 - val_loss: 0.3476\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3516 - val_loss: 0.3421\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3481 - val_loss: 0.3492\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3436 - val_loss: 0.3437\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3395 - val_loss: 0.3419\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3383 - val_loss: 0.3342\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3360 - val_loss: 0.3255\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3329 - val_loss: 0.3322\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3306 - val_loss: 0.3447\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3292 - val_loss: 0.3478\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3268 - val_loss: 0.3211\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3233 - val_loss: 0.3229\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3230 - val_loss: 0.3367\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3214 - val_loss: 0.3210\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3237 - val_loss: 0.3228\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3219 - val_loss: 0.3189\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3168 - val_loss: 0.3217\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3137 - val_loss: 0.3368\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3151 - val_loss: 0.3163\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3166 - val_loss: 0.3193\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3132 - val_loss: 0.3204\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3090 - val_loss: 0.3200\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3087 - val_loss: 0.3133\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3088 - val_loss: 0.3123\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3089 - val_loss: 0.3163\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3035 - val_loss: 0.3237\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3049 - val_loss: 0.3428\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3054 - val_loss: 0.3516\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3044 - val_loss: 0.3178\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3003 - val_loss: 0.3209\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3029 - val_loss: 0.3192\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3020 - val_loss: 0.3020\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2985 - val_loss: 0.3059\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2968 - val_loss: 0.3088\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2970 - val_loss: 0.3160\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2966 - val_loss: 0.3046\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2940 - val_loss: 0.3043\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2945 - val_loss: 0.3055\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2935 - val_loss: 0.3048\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2957 - val_loss: 0.3076\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2940 - val_loss: 0.3082\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2908 - val_loss: 0.3058\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3020\n",
      "Epoch 1/100\n",
      " 11/242 [>.............................] - ETA: 1s - loss: 4.0248  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:26:47.398795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/242 [============================>.] - ETA: 0s - loss: 0.9841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:26:48.667050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 0.9802 - val_loss: 0.5940\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5458 - val_loss: 0.4837\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4677 - val_loss: 0.4400\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4274 - val_loss: 0.4143\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4092 - val_loss: 0.4175\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3988 - val_loss: 0.3902\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3903 - val_loss: 0.3912\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3853 - val_loss: 0.3805\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3805 - val_loss: 0.3753\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3754 - val_loss: 0.3705\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3732 - val_loss: 0.3715\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3689 - val_loss: 0.3847\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3659 - val_loss: 0.3714\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3634 - val_loss: 0.3616\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3624 - val_loss: 0.3560\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3592 - val_loss: 0.3598\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3574 - val_loss: 0.3523\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3552 - val_loss: 0.3561\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3550 - val_loss: 0.3509\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3531 - val_loss: 0.3585\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3523 - val_loss: 0.3585\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3504 - val_loss: 0.3535\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3476 - val_loss: 0.3486\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3479 - val_loss: 0.3447\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3460 - val_loss: 0.3478\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3451 - val_loss: 0.3529\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3450 - val_loss: 0.3497\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3440 - val_loss: 0.3458\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3412 - val_loss: 0.3436\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3398 - val_loss: 0.3478\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3412 - val_loss: 0.3537\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3376 - val_loss: 0.3447\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3357 - val_loss: 0.3428\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3361 - val_loss: 0.3577\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3358 - val_loss: 0.3394\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3347 - val_loss: 0.3396\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3329 - val_loss: 0.3391\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3324 - val_loss: 0.3400\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3321 - val_loss: 0.3585\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3307 - val_loss: 0.3426\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3301 - val_loss: 0.3394\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3293 - val_loss: 0.3377\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3305 - val_loss: 0.3364\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3292 - val_loss: 0.3392\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3263 - val_loss: 0.3391\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3262 - val_loss: 0.3539\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3267 - val_loss: 0.3401\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3260 - val_loss: 0.3464\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3241 - val_loss: 0.3450\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3253 - val_loss: 0.3497\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3252 - val_loss: 0.3410\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3226 - val_loss: 0.3362\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3247 - val_loss: 0.3332\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3215 - val_loss: 0.3321\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3214 - val_loss: 0.3376\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3200 - val_loss: 0.3360\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3227 - val_loss: 0.3441\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3197 - val_loss: 0.3390\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3206 - val_loss: 0.3417\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3174 - val_loss: 0.3315\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3194 - val_loss: 0.3475\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3183 - val_loss: 0.3296\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3179 - val_loss: 0.3617\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3191 - val_loss: 0.3372\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3177 - val_loss: 0.3303\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3182 - val_loss: 0.3304\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3162 - val_loss: 0.3268\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3154 - val_loss: 0.3327\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3150 - val_loss: 0.3306\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3135 - val_loss: 0.3257\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3131 - val_loss: 0.3314\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3124 - val_loss: 0.3312\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3103 - val_loss: 0.3319\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3124 - val_loss: 0.3434\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3104 - val_loss: 0.3380\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3089 - val_loss: 0.3238\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3076 - val_loss: 0.3253\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3085 - val_loss: 0.3222\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3097 - val_loss: 0.3203\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3076 - val_loss: 0.3236\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3082 - val_loss: 0.3217\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3062 - val_loss: 0.3224\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3042 - val_loss: 0.3195\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3025 - val_loss: 0.3159\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3047 - val_loss: 0.3153\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3001 - val_loss: 0.3246\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3024 - val_loss: 0.3197\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3000 - val_loss: 0.3181\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3006 - val_loss: 0.3163\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3010 - val_loss: 0.3200\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2957 - val_loss: 0.3269\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2985 - val_loss: 0.3140\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2962 - val_loss: 0.3229\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2973 - val_loss: 0.3105\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2952 - val_loss: 0.3098\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2955 - val_loss: 0.3145\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2948 - val_loss: 0.3156\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2932 - val_loss: 0.3088\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2930 - val_loss: 0.3226\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2927 - val_loss: 0.3124\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3095\n",
      "Epoch 1/100\n",
      " 11/242 [>.............................] - ETA: 1s - loss: 4.0833 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:29:07.818164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 2.0757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:29:09.015969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 2.0757 - val_loss: 0.8343\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7628 - val_loss: 0.6876\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6713 - val_loss: 0.6436\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6310 - val_loss: 0.6089\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6005 - val_loss: 0.5834\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5762 - val_loss: 0.5610\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5545 - val_loss: 0.5422\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5352 - val_loss: 0.5248\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5181 - val_loss: 0.5094\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5036 - val_loss: 0.4954\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4914 - val_loss: 0.4849\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4805 - val_loss: 0.4757\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4713 - val_loss: 0.4672\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4632 - val_loss: 0.4605\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4565 - val_loss: 0.4555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4506 - val_loss: 0.4508\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4458 - val_loss: 0.4447\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4414 - val_loss: 0.4412\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4372 - val_loss: 0.4375\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4338 - val_loss: 0.4349\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4308 - val_loss: 0.4315\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4274 - val_loss: 0.4287\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4252 - val_loss: 0.4264\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4222 - val_loss: 0.4242\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4198 - val_loss: 0.4213\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4175 - val_loss: 0.4201\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4154 - val_loss: 0.4171\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4132 - val_loss: 0.4154\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4109 - val_loss: 0.4145\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4094 - val_loss: 0.4119\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4077 - val_loss: 0.4101\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4057 - val_loss: 0.4080\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4042 - val_loss: 0.4065\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4024 - val_loss: 0.4050\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4009 - val_loss: 0.4046\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3995 - val_loss: 0.4030\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3982 - val_loss: 0.4013\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3966 - val_loss: 0.3999\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3953 - val_loss: 0.3992\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3943 - val_loss: 0.3970\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3928 - val_loss: 0.3960\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3915 - val_loss: 0.3953\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3903 - val_loss: 0.3935\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3892 - val_loss: 0.3938\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3881 - val_loss: 0.3916\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3871 - val_loss: 0.3903\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3862 - val_loss: 0.3896\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3851 - val_loss: 0.3885\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3839 - val_loss: 0.3877\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3831 - val_loss: 0.3865\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3819 - val_loss: 0.3860\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3810 - val_loss: 0.3850\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3800 - val_loss: 0.3846\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3790 - val_loss: 0.3833\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3784 - val_loss: 0.3833\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3778 - val_loss: 0.3815\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3768 - val_loss: 0.3813\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3761 - val_loss: 0.3806\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3752 - val_loss: 0.3801\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3743 - val_loss: 0.3798\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3738 - val_loss: 0.3784\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3729 - val_loss: 0.3783\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3720 - val_loss: 0.3780\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3714 - val_loss: 0.3779\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3708 - val_loss: 0.3762\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3700 - val_loss: 0.3758\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3698 - val_loss: 0.3744\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3688 - val_loss: 0.3743\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3677 - val_loss: 0.3733\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3673 - val_loss: 0.3736\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3669 - val_loss: 0.3738\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3662 - val_loss: 0.3722\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3654 - val_loss: 0.3731\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3652 - val_loss: 0.3711\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3643 - val_loss: 0.3712\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3639 - val_loss: 0.3705\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3630 - val_loss: 0.3704\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3629 - val_loss: 0.3691\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3622 - val_loss: 0.3684\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3614 - val_loss: 0.3681\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3613 - val_loss: 0.3676\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3605 - val_loss: 0.3673\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3601 - val_loss: 0.3665\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3592 - val_loss: 0.3678\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3589 - val_loss: 0.3654\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3587 - val_loss: 0.3662\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3578 - val_loss: 0.3649\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3569 - val_loss: 0.3643\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3569 - val_loss: 0.3643\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3564 - val_loss: 0.3631\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3557 - val_loss: 0.3629\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3552 - val_loss: 0.3624\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3548 - val_loss: 0.3619\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3542 - val_loss: 0.3611\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3537 - val_loss: 0.3611\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3530 - val_loss: 0.3613\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3527 - val_loss: 0.3608\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3522 - val_loss: 0.3603\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3517 - val_loss: 0.3602\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3514 - val_loss: 0.3596\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3929\n",
      "Epoch 1/100\n",
      " 23/242 [=>............................] - ETA: 1s - loss: 3.7221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:31:20.172819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.4397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:31:21.405760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 1.4397 - val_loss: 0.7650\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7497 - val_loss: 0.6758\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6807 - val_loss: 0.6191\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6287 - val_loss: 0.5735\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5864 - val_loss: 0.5403\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5547 - val_loss: 0.5155\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5306 - val_loss: 0.4949\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5112 - val_loss: 0.4837\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4985 - val_loss: 0.4702\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4872 - val_loss: 0.4607\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4785 - val_loss: 0.4534\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4718 - val_loss: 0.4471\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4652 - val_loss: 0.4407\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4596 - val_loss: 0.4362\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4552 - val_loss: 0.4310\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4509 - val_loss: 0.4281\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4465 - val_loss: 0.4252\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4436 - val_loss: 0.4211\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4400 - val_loss: 0.4193\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4379 - val_loss: 0.4162\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4352 - val_loss: 0.4126\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4323 - val_loss: 0.4099\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4302 - val_loss: 0.4078\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4280 - val_loss: 0.4058\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4257 - val_loss: 0.4042\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4241 - val_loss: 0.4016\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4221 - val_loss: 0.4013\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4201 - val_loss: 0.3988\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4179 - val_loss: 0.3981\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4163 - val_loss: 0.3958\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4145 - val_loss: 0.3936\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4127 - val_loss: 0.3926\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4113 - val_loss: 0.3906\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4094 - val_loss: 0.3908\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4083 - val_loss: 0.3877\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4062 - val_loss: 0.3859\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4050 - val_loss: 0.3851\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4033 - val_loss: 0.3851\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4022 - val_loss: 0.3828\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4010 - val_loss: 0.3818\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4000 - val_loss: 0.3813\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3985 - val_loss: 0.3802\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3976 - val_loss: 0.3792\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3966 - val_loss: 0.3781\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3956 - val_loss: 0.3778\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3945 - val_loss: 0.3766\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3936 - val_loss: 0.3769\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3926 - val_loss: 0.3756\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3917 - val_loss: 0.3754\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3912 - val_loss: 0.3742\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3899 - val_loss: 0.3728\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3893 - val_loss: 0.3717\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3880 - val_loss: 0.3723\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3876 - val_loss: 0.3706\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3865 - val_loss: 0.3722\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3859 - val_loss: 0.3705\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3852 - val_loss: 0.3693\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3843 - val_loss: 0.3682\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3837 - val_loss: 0.3691\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3826 - val_loss: 0.3683\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3820 - val_loss: 0.3668\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3814 - val_loss: 0.3655\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3811 - val_loss: 0.3654\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3800 - val_loss: 0.3659\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3796 - val_loss: 0.3644\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3791 - val_loss: 0.3645\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3785 - val_loss: 0.3639\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3782 - val_loss: 0.3633\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3774 - val_loss: 0.3627\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3770 - val_loss: 0.3625\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3763 - val_loss: 0.3634\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3758 - val_loss: 0.3606\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3751 - val_loss: 0.3618\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3744 - val_loss: 0.3600\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3743 - val_loss: 0.3595\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3736 - val_loss: 0.3587\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3730 - val_loss: 0.3587\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.3578\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3719 - val_loss: 0.3572\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3711 - val_loss: 0.3569\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3713 - val_loss: 0.3565\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3704 - val_loss: 0.3563\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3700 - val_loss: 0.3569\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3691 - val_loss: 0.3563\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3694 - val_loss: 0.3547\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3683 - val_loss: 0.3558\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3677 - val_loss: 0.3551\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3674 - val_loss: 0.3544\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3667 - val_loss: 0.3544\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3663 - val_loss: 0.3526\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3651 - val_loss: 0.3519\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3649 - val_loss: 0.3518\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3643 - val_loss: 0.3513\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3638 - val_loss: 0.3518\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3634 - val_loss: 0.3509\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3630 - val_loss: 0.3512\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3627 - val_loss: 0.3497\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3621 - val_loss: 0.3493\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3616 - val_loss: 0.3494\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3614 - val_loss: 0.3485\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3427\n",
      "Epoch 1/100\n",
      " 12/242 [>.............................] - ETA: 1s - loss: 3.8680 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:33:33.197729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.7536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:33:34.381755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 1.7536 - val_loss: 0.9761\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8649 - val_loss: 0.7639\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7087 - val_loss: 0.6681\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6341 - val_loss: 0.6058\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5863 - val_loss: 0.5653\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5548 - val_loss: 0.5365\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5309 - val_loss: 0.5143\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5113 - val_loss: 0.4963\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4954 - val_loss: 0.4831\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4818 - val_loss: 0.4688\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4698 - val_loss: 0.4582\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4603 - val_loss: 0.4495\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4521 - val_loss: 0.4411\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4454 - val_loss: 0.4356\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4393 - val_loss: 0.4316\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4344 - val_loss: 0.4255\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4297 - val_loss: 0.4213\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4262 - val_loss: 0.4186\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4224 - val_loss: 0.4156\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4192 - val_loss: 0.4144\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4166 - val_loss: 0.4101\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4138 - val_loss: 0.4080\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4113 - val_loss: 0.4050\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4089 - val_loss: 0.4024\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4072 - val_loss: 0.4022\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4047 - val_loss: 0.3987\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4031 - val_loss: 0.3969\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4011 - val_loss: 0.3951\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3995 - val_loss: 0.3928\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3980 - val_loss: 0.3923\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3962 - val_loss: 0.3899\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3947 - val_loss: 0.3895\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3934 - val_loss: 0.3877\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3922 - val_loss: 0.3862\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3906 - val_loss: 0.3849\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3894 - val_loss: 0.3839\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3883 - val_loss: 0.3827\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3872 - val_loss: 0.3814\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3857 - val_loss: 0.3805\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3848 - val_loss: 0.3794\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3836 - val_loss: 0.3779\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3830 - val_loss: 0.3772\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3820 - val_loss: 0.3763\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3809 - val_loss: 0.3766\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3803 - val_loss: 0.3745\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3787 - val_loss: 0.3734\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3783 - val_loss: 0.3728\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3774 - val_loss: 0.3723\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3765 - val_loss: 0.3709\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3756 - val_loss: 0.3703\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3750 - val_loss: 0.3698\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3741 - val_loss: 0.3691\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3731 - val_loss: 0.3699\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3723 - val_loss: 0.3666\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3717 - val_loss: 0.3674\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3711 - val_loss: 0.3669\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3706 - val_loss: 0.3653\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3698 - val_loss: 0.3654\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3686 - val_loss: 0.3650\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3683 - val_loss: 0.3648\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3679 - val_loss: 0.3629\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3668 - val_loss: 0.3624\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3665 - val_loss: 0.3618\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3657 - val_loss: 0.3619\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3654 - val_loss: 0.3606\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3642 - val_loss: 0.3605\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3639 - val_loss: 0.3592\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3634 - val_loss: 0.3603\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3628 - val_loss: 0.3593\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3617 - val_loss: 0.3580\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3611 - val_loss: 0.3586\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3606 - val_loss: 0.3580\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3603 - val_loss: 0.3573\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3598 - val_loss: 0.3556\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3596 - val_loss: 0.3548\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3587 - val_loss: 0.3560\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3583 - val_loss: 0.3544\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3579 - val_loss: 0.3549\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3573 - val_loss: 0.3535\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3564 - val_loss: 0.3537\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3559 - val_loss: 0.3525\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3561 - val_loss: 0.3519\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3548 - val_loss: 0.3518\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3545 - val_loss: 0.3518\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3542 - val_loss: 0.3511\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3540 - val_loss: 0.3504\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3533 - val_loss: 0.3513\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3530 - val_loss: 0.3494\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3523 - val_loss: 0.3495\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3517 - val_loss: 0.3489\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3515 - val_loss: 0.3479\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3508 - val_loss: 0.3495\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3510 - val_loss: 0.3474\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3501 - val_loss: 0.3481\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3499 - val_loss: 0.3480\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3491 - val_loss: 0.3475\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3490 - val_loss: 0.3472\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3491 - val_loss: 0.3459\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3484 - val_loss: 0.3453\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3479 - val_loss: 0.3450\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3569\n",
      "Epoch 1/100\n",
      " 10/242 [>.............................] - ETA: 1s - loss: 4.6191  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:35:45.308533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.7919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:35:46.692336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 1.7919 - val_loss: 0.8437\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.8059 - val_loss: 0.7368\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7046 - val_loss: 0.6842\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6575 - val_loss: 0.6400\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6201 - val_loss: 0.6076\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5872 - val_loss: 0.5765\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5614 - val_loss: 0.5525\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5380 - val_loss: 0.5289\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5160 - val_loss: 0.5090\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4964 - val_loss: 0.4930\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4816 - val_loss: 0.4798\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4674 - val_loss: 0.4651\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4532 - val_loss: 0.4554\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4446 - val_loss: 0.4454\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4349 - val_loss: 0.4374\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4262 - val_loss: 0.4307\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4193 - val_loss: 0.4246\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4151 - val_loss: 0.4190\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4083 - val_loss: 0.4135\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4057 - val_loss: 0.4091\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3996 - val_loss: 0.4055\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3955 - val_loss: 0.4013\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3929 - val_loss: 0.3983\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3902 - val_loss: 0.3961\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3881 - val_loss: 0.3926\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3880 - val_loss: 0.3899\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3836 - val_loss: 0.3881\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3778 - val_loss: 0.3856\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3755 - val_loss: 0.3840\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3751 - val_loss: 0.3817\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3709 - val_loss: 0.3798\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3682 - val_loss: 0.3804\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3700 - val_loss: 0.3800\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3696 - val_loss: 0.3749\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3678 - val_loss: 0.3755\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3652 - val_loss: 0.3731\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3608 - val_loss: 0.3700\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3583 - val_loss: 0.3731\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3596 - val_loss: 0.3687\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3563 - val_loss: 0.3658\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3536 - val_loss: 0.3654\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3559 - val_loss: 0.3648\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3564 - val_loss: 0.3655\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3511 - val_loss: 0.3615\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3493 - val_loss: 0.3604\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3475 - val_loss: 0.3600\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3489 - val_loss: 0.3593\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3504 - val_loss: 0.3593\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3454 - val_loss: 0.3563\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3426 - val_loss: 0.3572\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3410 - val_loss: 0.3596\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3436 - val_loss: 0.3557\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3390 - val_loss: 0.3537\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3382 - val_loss: 0.3527\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3398 - val_loss: 0.3518\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3361 - val_loss: 0.3519\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3379 - val_loss: 0.3523\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3381 - val_loss: 0.3497\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3375 - val_loss: 0.3489\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3381 - val_loss: 0.3487\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3336 - val_loss: 0.3481\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3318 - val_loss: 0.3464\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3303 - val_loss: 0.3460\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3318 - val_loss: 0.3464\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3323 - val_loss: 0.3465\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3293 - val_loss: 0.3436\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3273 - val_loss: 0.3428\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3300 - val_loss: 0.3429\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3298 - val_loss: 0.3422\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3300 - val_loss: 0.3442\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3244 - val_loss: 0.3444\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3236 - val_loss: 0.3413\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3245 - val_loss: 0.3402\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3261 - val_loss: 0.3390\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3216 - val_loss: 0.3397\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3235 - val_loss: 0.3395\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3210 - val_loss: 0.3380\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3216 - val_loss: 0.3392\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3191 - val_loss: 0.3373\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3208 - val_loss: 0.3368\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3181 - val_loss: 0.3362\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3170 - val_loss: 0.3359\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3180 - val_loss: 0.3357\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3193 - val_loss: 0.3358\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3182 - val_loss: 0.3355\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3152 - val_loss: 0.3331\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3132 - val_loss: 0.3333\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3128 - val_loss: 0.3330\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3147 - val_loss: 0.3323\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3119 - val_loss: 0.3317\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3129 - val_loss: 0.3328\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3145 - val_loss: 0.3308\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3116 - val_loss: 0.3293\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3100 - val_loss: 0.3319\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3112 - val_loss: 0.3313\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3091 - val_loss: 0.3286\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3094 - val_loss: 0.3288\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3098 - val_loss: 0.3278\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3091 - val_loss: 0.3273\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3061 - val_loss: 0.3272\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3486\n",
      "Epoch 1/100\n",
      "  9/242 [>.............................] - ETA: 1s - loss: 5.6991  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:38:22.566765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 2.2869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:38:24.020744: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 3s 7ms/step - loss: 2.2869 - val_loss: 0.9796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8700 - val_loss: 0.7641\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7449 - val_loss: 0.6938\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6929 - val_loss: 0.6531\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6569 - val_loss: 0.6202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6266 - val_loss: 0.5907\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6004 - val_loss: 0.5658\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5765 - val_loss: 0.5438\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5548 - val_loss: 0.5235\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5358 - val_loss: 0.5058\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5184 - val_loss: 0.4909\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5028 - val_loss: 0.4759\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4890 - val_loss: 0.4643\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4763 - val_loss: 0.4530\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4660 - val_loss: 0.4438\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4563 - val_loss: 0.4350\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4479 - val_loss: 0.4286\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4407 - val_loss: 0.4218\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4341 - val_loss: 0.4164\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4286 - val_loss: 0.4116\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4234 - val_loss: 0.4077\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4185 - val_loss: 0.4037\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4144 - val_loss: 0.3999\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4105 - val_loss: 0.3971\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4070 - val_loss: 0.3941\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4035 - val_loss: 0.3915\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4009 - val_loss: 0.3888\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3973 - val_loss: 0.3873\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3957 - val_loss: 0.3851\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3935 - val_loss: 0.3830\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3906 - val_loss: 0.3819\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3887 - val_loss: 0.3794\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3866 - val_loss: 0.3773\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3841 - val_loss: 0.3760\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3829 - val_loss: 0.3743\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3808 - val_loss: 0.3732\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3791 - val_loss: 0.3714\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3774 - val_loss: 0.3705\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3754 - val_loss: 0.3694\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3740 - val_loss: 0.3686\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3730 - val_loss: 0.3670\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3712 - val_loss: 0.3665\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3696 - val_loss: 0.3655\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3685 - val_loss: 0.3640\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3674 - val_loss: 0.3625\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3659 - val_loss: 0.3619\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3652 - val_loss: 0.3605\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3637 - val_loss: 0.3606\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3626 - val_loss: 0.3596\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3616 - val_loss: 0.3580\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3602 - val_loss: 0.3582\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3597 - val_loss: 0.3567\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3582 - val_loss: 0.3578\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3575 - val_loss: 0.3560\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3557 - val_loss: 0.3554\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3552 - val_loss: 0.3542\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3543 - val_loss: 0.3536\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3536 - val_loss: 0.3523\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3521 - val_loss: 0.3514\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3512 - val_loss: 0.3505\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3506 - val_loss: 0.3507\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3498 - val_loss: 0.3495\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3486 - val_loss: 0.3504\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3484 - val_loss: 0.3484\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3471 - val_loss: 0.3474\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3462 - val_loss: 0.3479\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3455 - val_loss: 0.3488\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3445 - val_loss: 0.3460\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3441 - val_loss: 0.3451\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3435 - val_loss: 0.3442\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3423 - val_loss: 0.3438\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3414 - val_loss: 0.3438\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3409 - val_loss: 0.3437\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3402 - val_loss: 0.3426\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3392 - val_loss: 0.3423\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3389 - val_loss: 0.3427\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3385 - val_loss: 0.3404\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3373 - val_loss: 0.3418\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3368 - val_loss: 0.3405\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3362 - val_loss: 0.3403\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3357 - val_loss: 0.3399\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3352 - val_loss: 0.3384\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3344 - val_loss: 0.3387\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3338 - val_loss: 0.3381\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3332 - val_loss: 0.3381\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3325 - val_loss: 0.3371\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3320 - val_loss: 0.3374\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3314 - val_loss: 0.3355\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3308 - val_loss: 0.3352\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3301 - val_loss: 0.3354\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3301 - val_loss: 0.3339\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3294 - val_loss: 0.3335\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3289 - val_loss: 0.3339\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3282 - val_loss: 0.3326\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3277 - val_loss: 0.3337\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3271 - val_loss: 0.3331\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3266 - val_loss: 0.3333\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3262 - val_loss: 0.3319\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3254 - val_loss: 0.3313\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3248 - val_loss: 0.3325\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3298\n",
      "Epoch 1/100\n",
      "  9/242 [>.............................] - ETA: 1s - loss: 5.0715  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:41:04.325211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 2.0462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:41:05.802577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 2.0462 - val_loss: 0.9145\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.8449 - val_loss: 0.7416\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7163 - val_loss: 0.6816\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6687 - val_loss: 0.6444\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6330 - val_loss: 0.6114\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6049 - val_loss: 0.5863\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5786 - val_loss: 0.5631\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5549 - val_loss: 0.5409\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5358 - val_loss: 0.5230\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5185 - val_loss: 0.5068\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5037 - val_loss: 0.4958\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4903 - val_loss: 0.4800\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4797 - val_loss: 0.4709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4694 - val_loss: 0.4616\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4614 - val_loss: 0.4543\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4536 - val_loss: 0.4479\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4468 - val_loss: 0.4425\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4411 - val_loss: 0.4366\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4352 - val_loss: 0.4304\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4302 - val_loss: 0.4268\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4256 - val_loss: 0.4211\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4211 - val_loss: 0.4181\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4167 - val_loss: 0.4134\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4125 - val_loss: 0.4090\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4093 - val_loss: 0.4056\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4051 - val_loss: 0.4019\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4023 - val_loss: 0.3985\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3986 - val_loss: 0.3964\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3958 - val_loss: 0.3927\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3929 - val_loss: 0.3900\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3901 - val_loss: 0.3871\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3883 - val_loss: 0.3854\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3853 - val_loss: 0.3838\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3831 - val_loss: 0.3806\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3812 - val_loss: 0.3788\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3791 - val_loss: 0.3766\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3765 - val_loss: 0.3748\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3750 - val_loss: 0.3737\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3734 - val_loss: 0.3712\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3719 - val_loss: 0.3689\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3700 - val_loss: 0.3675\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3684 - val_loss: 0.3661\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3666 - val_loss: 0.3653\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3653 - val_loss: 0.3633\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3638 - val_loss: 0.3632\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3626 - val_loss: 0.3609\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3613 - val_loss: 0.3601\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3597 - val_loss: 0.3593\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3589 - val_loss: 0.3582\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3573 - val_loss: 0.3589\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3565 - val_loss: 0.3566\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3555 - val_loss: 0.3571\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3543 - val_loss: 0.3538\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3533 - val_loss: 0.3534\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3524 - val_loss: 0.3525\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3513 - val_loss: 0.3528\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3498 - val_loss: 0.3514\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3493 - val_loss: 0.3500\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3488 - val_loss: 0.3491\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3480 - val_loss: 0.3484\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3464 - val_loss: 0.3500\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3458 - val_loss: 0.3477\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3443 - val_loss: 0.3488\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3442 - val_loss: 0.3492\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3436 - val_loss: 0.3471\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3430 - val_loss: 0.3470\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3418 - val_loss: 0.3442\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3411 - val_loss: 0.3439\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3408 - val_loss: 0.3442\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3399 - val_loss: 0.3431\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3388 - val_loss: 0.3417\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3385 - val_loss: 0.3412\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3377 - val_loss: 0.3413\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3371 - val_loss: 0.3406\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3365 - val_loss: 0.3398\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3359 - val_loss: 0.3395\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3352 - val_loss: 0.3386\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3340 - val_loss: 0.3426\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3339 - val_loss: 0.3395\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3338 - val_loss: 0.3377\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3332 - val_loss: 0.3386\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3316 - val_loss: 0.3363\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3315 - val_loss: 0.3361\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3310 - val_loss: 0.3369\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3308 - val_loss: 0.3355\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3299 - val_loss: 0.3362\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3293 - val_loss: 0.3350\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3290 - val_loss: 0.3349\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3283 - val_loss: 0.3371\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3283 - val_loss: 0.3346\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3277 - val_loss: 0.3343\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3272 - val_loss: 0.3339\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3267 - val_loss: 0.3334\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3259 - val_loss: 0.3322\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3256 - val_loss: 0.3330\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3251 - val_loss: 0.3322\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3250 - val_loss: 0.3337\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3241 - val_loss: 0.3315\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3237 - val_loss: 0.3329\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3232 - val_loss: 0.3343\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3392\n",
      "Epoch 1/100\n",
      " 10/242 [>.............................] - ETA: 1s - loss: 4.5495  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:43:41.098489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 0.9154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:43:42.397489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.9154 - val_loss: 0.5217\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4726 - val_loss: 0.4342\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4182 - val_loss: 0.4085\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3952 - val_loss: 0.3951\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3833 - val_loss: 0.3807\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3736 - val_loss: 0.3746\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3636 - val_loss: 0.3735\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3565 - val_loss: 0.3590\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3513 - val_loss: 0.3612\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3439 - val_loss: 0.3480\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3417 - val_loss: 0.3503\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3380 - val_loss: 0.3521\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3320 - val_loss: 0.3370\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3271 - val_loss: 0.3361\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3252 - val_loss: 0.3463\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3222 - val_loss: 0.3372\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3163 - val_loss: 0.3385\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3157 - val_loss: 0.3334\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3130 - val_loss: 0.3281\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3104 - val_loss: 0.3270\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3078 - val_loss: 0.3475\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3073 - val_loss: 0.3272\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3076 - val_loss: 0.3178\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3017 - val_loss: 0.3183\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3018 - val_loss: 0.3280\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3001 - val_loss: 0.3318\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2986 - val_loss: 0.3178\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2985 - val_loss: 0.3296\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2962 - val_loss: 0.3256\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2959 - val_loss: 0.3193\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2956 - val_loss: 0.3113\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2934 - val_loss: 0.3175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2895 - val_loss: 0.3158\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2919 - val_loss: 0.3214\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2922 - val_loss: 0.3183\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2883 - val_loss: 0.3214\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2890 - val_loss: 0.3092\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2884 - val_loss: 0.3058\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2886 - val_loss: 0.3060\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2866 - val_loss: 0.3028\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2839 - val_loss: 0.3092\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2837 - val_loss: 0.3051\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2840 - val_loss: 0.3106\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2847 - val_loss: 0.3035\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2809 - val_loss: 0.3053\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2813 - val_loss: 0.3023\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2787 - val_loss: 0.3030\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2787 - val_loss: 0.3007\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2784 - val_loss: 0.3097\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2812 - val_loss: 0.3108\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2782 - val_loss: 0.2984\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2761 - val_loss: 0.3030\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2761 - val_loss: 0.3022\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2779 - val_loss: 0.3096\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2767 - val_loss: 0.3077\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2745 - val_loss: 0.3088\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2734 - val_loss: 0.2979\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2746 - val_loss: 0.3032\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2755 - val_loss: 0.3046\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2724 - val_loss: 0.2991\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2711 - val_loss: 0.3081\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2691 - val_loss: 0.3008\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2722 - val_loss: 0.2953\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2700 - val_loss: 0.2977\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2694 - val_loss: 0.2994\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2681 - val_loss: 0.3086\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2681 - val_loss: 0.3048\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2668 - val_loss: 0.2952\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2679 - val_loss: 0.3133\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2687 - val_loss: 0.3176\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2669 - val_loss: 0.2940\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2680 - val_loss: 0.2942\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2657 - val_loss: 0.2989\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2659 - val_loss: 0.2967\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2632 - val_loss: 0.3019\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2659 - val_loss: 0.2992\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2640 - val_loss: 0.2968\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2658 - val_loss: 0.2974\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2634 - val_loss: 0.2966\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2621 - val_loss: 0.3098\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2628 - val_loss: 0.2986\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3113\n",
      "Epoch 1/100\n",
      " 21/242 [=>............................] - ETA: 1s - loss: 1.9819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:45:37.694877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.2512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:45:38.970373: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 6ms/step - loss: 1.2512 - val_loss: 0.6157\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 1.9610 - val_loss: 1.3214\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 4427.7007 - val_loss: 56277151744.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 1/100\n",
      " 10/242 [>.............................] - ETA: 1s - loss: 3.2781  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:45:54.535802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 0.7957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:45:55.904871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7957 - val_loss: 0.5143\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 6.2654 - val_loss: 0.5039\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 131.9778 - val_loss: 1.4699\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.9464 - val_loss: 0.7074\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7032 - val_loss: 0.6449\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6423 - val_loss: 0.5999\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6036 - val_loss: 0.5476\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5667 - val_loss: 0.5102\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5309 - val_loss: 0.4868\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5145 - val_loss: 0.5509\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5069 - val_loss: 0.4725\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4938 - val_loss: 0.4640\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4936 - val_loss: 0.4639\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4906 - val_loss: 0.4569\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4878 - val_loss: 0.4659\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4821 - val_loss: 0.4631\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4826 - val_loss: 0.4570\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4807 - val_loss: 0.4539\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4800 - val_loss: 0.4657\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4786 - val_loss: 0.4536\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4747 - val_loss: 0.4631\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4721 - val_loss: 0.4386\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4684 - val_loss: 0.4426\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4641 - val_loss: 0.4463\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4599 - val_loss: 0.4327\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4596 - val_loss: 0.4350\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4590 - val_loss: 0.4349\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4552 - val_loss: 0.4413\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4519 - val_loss: 0.4344\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4538 - val_loss: 0.4432\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4799 - val_loss: 0.4842\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4599 - val_loss: 0.4242\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4504 - val_loss: 0.4435\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4470 - val_loss: 0.4214\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4437 - val_loss: 0.4300\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4374 - val_loss: 0.4108\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4343 - val_loss: 0.4254\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4294 - val_loss: 0.4087\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4289 - val_loss: 0.4253\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4253 - val_loss: 0.4204\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4256 - val_loss: 0.4326\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4234 - val_loss: 0.3992\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4286 - val_loss: 0.4016\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4247 - val_loss: 0.4068\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4214 - val_loss: 0.4061\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4218 - val_loss: 0.4022\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4209 - val_loss: 0.3971\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4198 - val_loss: 0.4003\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4195 - val_loss: 0.4007\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4194 - val_loss: 0.4024\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4175 - val_loss: 0.4027\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4180 - val_loss: 0.4007\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4177 - val_loss: 0.4028\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4145 - val_loss: 0.4110\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4163 - val_loss: 0.4195\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4141 - val_loss: 0.4041\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4146 - val_loss: 0.3995\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4398\n",
      "Epoch 1/100\n",
      " 27/242 [==>...........................] - ETA: 0s - loss: 4.3734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:47:20.361542: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - ETA: 0s - loss: 1.4663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:47:21.379777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.4663 - val_loss: 0.6949\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7357 - val_loss: 0.6286\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7398 - val_loss: 0.6228\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.4218 - val_loss: 0.7905\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 13.2657 - val_loss: 2.3813\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 63.7922 - val_loss: 12.9680\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1062.1302 - val_loss: 118.0177\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 4944.9351 - val_loss: 1002.4811\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 49483.2148 - val_loss: 8816.1562\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 462268.0312 - val_loss: 80827.0234\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 3856705.5000 - val_loss: 745427.6250\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 35628720.0000 - val_loss: 6824676.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 639800256.0000 - val_loss: 62490068.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 22205468.0000\n",
      "Epoch 1/100\n",
      " 27/242 [==>...........................] - ETA: 0s - loss: 4.2071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:47:36.654097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/242 [============================>.] - ETA: 0s - loss: 1.5266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:47:37.702848: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 5ms/step - loss: 1.5240 - val_loss: 0.5930\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9698 - val_loss: 0.6429\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9257 - val_loss: 0.5289\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.2902 - val_loss: 0.7103\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.6326 - val_loss: 0.5912\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 2.5015 - val_loss: 0.8243\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 2.9745 - val_loss: 0.7382\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 5.0380 - val_loss: 1.1527\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 7.0689 - val_loss: 1.0758\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 11.9992 - val_loss: 2.0295\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 16.9732 - val_loss: 2.2057\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 28.2372 - val_loss: 4.2702\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 43.0293 - val_loss: 5.5541\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 209.6996\n",
      "Epoch 1/100\n",
      " 27/242 [==>...........................] - ETA: 0s - loss: 5.3132"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:47:52.646515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/242 [============================>.] - ETA: 0s - loss: 1.7109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:47:53.676727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.7072 - val_loss: 0.6295\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7525 - val_loss: 0.5462\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.8358 - val_loss: 1.0260\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 6.7264 - val_loss: 1.8054\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 31.5176 - val_loss: 9.7091\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 152.7486 - val_loss: 41.0308\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 790.9796 - val_loss: 209.1393\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 3754.6243 - val_loss: 1088.0309\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 19564.6445 - val_loss: 5184.1963\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 102329.1250 - val_loss: 25420.3496\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 496059.8750 - val_loss: 128517.5938\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 2767780.0000 - val_loss: 634984.8125\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 18094524.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amqo/Develop/ML/miniconda3/envs/handsOnTensorflow/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [-4.04170712e-01 -3.43181173e-01 -3.43051056e-01 -8.71818970e+23\n",
      " -5.26007523e-01 -3.16648126e-01 -3.64183545e-01 -3.39184821e-01\n",
      "             nan -1.34334006e+07]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/363 [..............................] - ETA: 2s - loss: 4.6453  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:48:07.966463: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - ETA: 0s - loss: 1.1889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 16:48:09.999262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 3s 6ms/step - loss: 1.1889 - val_loss: 0.5868\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.6341 - val_loss: 0.4830\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4567 - val_loss: 0.4267\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4249 - val_loss: 0.4031\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4095 - val_loss: 0.4219\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3954 - val_loss: 0.3959\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3890 - val_loss: 0.3882\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3807 - val_loss: 0.3788\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3726 - val_loss: 0.3742\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3654 - val_loss: 0.3598\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3589 - val_loss: 0.3689\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3537 - val_loss: 0.3497\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3482 - val_loss: 0.3423\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3459 - val_loss: 0.3504\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3404 - val_loss: 0.3394\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3362 - val_loss: 0.3405\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3329 - val_loss: 0.3337\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3310 - val_loss: 0.3358\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3294 - val_loss: 0.3253\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3264 - val_loss: 0.3309\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3248 - val_loss: 0.3319\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3230 - val_loss: 0.3249\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3216 - val_loss: 0.3188\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3210 - val_loss: 0.3184\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3181 - val_loss: 0.3201\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3171 - val_loss: 0.3203\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3146 - val_loss: 0.3246\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3141 - val_loss: 0.3171\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3138 - val_loss: 0.3250\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3123 - val_loss: 0.3250\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3106 - val_loss: 0.3125\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3098 - val_loss: 0.3258\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3089 - val_loss: 0.3193\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3070 - val_loss: 0.3192\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3067 - val_loss: 0.3189\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3058 - val_loss: 0.3153\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3049 - val_loss: 0.3083\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3047 - val_loss: 0.3205\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3053 - val_loss: 0.3189\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3075 - val_loss: 0.3089\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3022 - val_loss: 0.3071\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3000 - val_loss: 0.3142\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2982 - val_loss: 0.3228\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2969 - val_loss: 0.3092\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2976 - val_loss: 0.3080\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2964 - val_loss: 0.3198\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2957 - val_loss: 0.3210\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2970 - val_loss: 0.3033\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 16s 45ms/step - loss: 0.2949 - val_loss: 0.3058\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2945 - val_loss: 0.3108\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2929 - val_loss: 0.3103\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2930 - val_loss: 0.3122\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 45s 124ms/step - loss: 0.2921 - val_loss: 0.3036\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2921 - val_loss: 0.3066\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2912 - val_loss: 0.3003\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 44s 121ms/step - loss: 0.2901 - val_loss: 0.3045\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2908 - val_loss: 0.2970\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2886 - val_loss: 0.3039\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2881 - val_loss: 0.3045\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 42s 117ms/step - loss: 0.2882 - val_loss: 0.3058\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2862 - val_loss: 0.2969\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2884 - val_loss: 0.2990\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2848 - val_loss: 0.2994\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2875 - val_loss: 0.2957\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 43s 118ms/step - loss: 0.2875 - val_loss: 0.3345\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2876 - val_loss: 0.2996\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2846 - val_loss: 0.2962\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2862 - val_loss: 0.2948\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2856 - val_loss: 0.2978\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 42s 117ms/step - loss: 0.2831 - val_loss: 0.3007\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2831 - val_loss: 0.2935\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2841 - val_loss: 0.2943\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2823 - val_loss: 0.2997\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2810 - val_loss: 0.2992\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 42s 117ms/step - loss: 0.2828 - val_loss: 0.2986\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2820 - val_loss: 0.2936\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2821 - val_loss: 0.2962\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2822 - val_loss: 0.3015\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 43s 118ms/step - loss: 0.2811 - val_loss: 0.2985\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2795 - val_loss: 0.2968\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2804 - val_loss: 0.3271\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x31d4151c0&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x307151b50&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x31d4151c0&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x307151b50&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x31d4151c0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x31d4151c0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x31d4151c0>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x307151b50>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We explore the nmber of hidden layers, number of neuros and learning rate\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d1c9c6aa-6b28-4755-8955-6749c6b6cc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.010458464896594745, 'n_hidden': 3, 'n_neurons': 17}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "896e6ac9-4ee8-409f-a5aa-2328d6e26594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31664812564849854"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "990f1b95-5862-4f4f-b35e-ef63f1361b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d5abe084-acdf-4d7f-8ec3-73a414eac7b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2798 - val_loss: 0.2931\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2802 - val_loss: 0.2937\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2783 - val_loss: 0.2921\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2778 - val_loss: 0.2990\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2770 - val_loss: 0.3017\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2779 - val_loss: 0.2986\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2778 - val_loss: 0.2933\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2776 - val_loss: 0.2920\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2768 - val_loss: 0.2918\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2774 - val_loss: 0.2978\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2779 - val_loss: 0.2938\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2768 - val_loss: 0.2906\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2767 - val_loss: 0.2929\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2753 - val_loss: 0.2942\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2754 - val_loss: 0.2897\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2750 - val_loss: 0.3076\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2744 - val_loss: 0.2989\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2752 - val_loss: 0.2929\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2741 - val_loss: 0.2918\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2747 - val_loss: 0.2897\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2735 - val_loss: 0.3334\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2731 - val_loss: 0.2976\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2735 - val_loss: 0.2949\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2722 - val_loss: 0.3006\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2722 - val_loss: 0.2933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x33239a850>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "182dd14f-4291-4cb5-b0ff-6c4bf9ebddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7deffb-12d9-4678-8a52-41ec99126247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
